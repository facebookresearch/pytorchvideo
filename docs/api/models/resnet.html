


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>pytorchvideo.models.resnet &mdash; PyTorchVideo  documentation</title>
  

  
  
    <link rel="shortcut icon" href="../../_static/favicon.png"/>
  
  
  
    <link rel="canonical" href="https://pytorchvideo.org/docs/api/models/resnet.html"/>
  

  

  
  
    

  

  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" /> -->
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="pytorchvideo.models.net" href="net.html" />
    <link rel="prev" title="Models API" href="index.html" /> 

  
  <script src="../../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorchvideo.org" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorchvideo.org">Home</a>
          </li>
          <li>
            <a href="https://pytorchvideo.org/docs/tutorial_overview">Tutorials</a>
          </li>
          <li>
            <a href="https://github.com/facebookresearch/pytorchvideo/">Github</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>


<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Models</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../docs/models.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../docs/model_zoo.html">Model Zoo and Benchmarks</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Models API</a></li>
</ul>
<p class="caption"><span class="caption-text">Data</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../docs/data.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../docs/data_preparation.html">Data Preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../data/index.html">Data API</a></li>
</ul>
<p class="caption"><span class="caption-text">Transforms</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../docs/transforms.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../transforms/index.html">Transforms API</a></li>
</ul>
<p class="caption"><span class="caption-text">Layers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../docs/layers.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../layers/index.html">Layers API</a></li>
</ul>
<p class="caption"><span class="caption-text">Accelerator</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../docs/accelerator.html">Overview</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="index.html">Models API</a> &gt;</li>
        
      <li>pytorchvideo.models.resnet</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="../../_sources/api/models/resnet.rst.txt" rel="nofollow"><img src="../../_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <div class="section" id="pytorchvideo-models-resnet">
<h1>pytorchvideo.models.resnet<a class="headerlink" href="#pytorchvideo-models-resnet" title="Permalink to this headline">¶</a></h1>
<p>Building blocks for Resnet and resnet-like models</p>
<span class="target" id="module-pytorchvideo.models.resnet"></span><dl class="py function">
<dt id="pytorchvideo.models.resnet.create_bottleneck_block">
<code class="sig-prename descclassname">pytorchvideo.models.resnet.</code><code class="sig-name descname">create_bottleneck_block</code><span class="sig-paren">(</span><em class="sig-param">*</em>, <em class="sig-param">dim_in</em>, <em class="sig-param">dim_inner</em>, <em class="sig-param">dim_out</em>, <em class="sig-param">conv_a_kernel_size=(3</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em>, <em class="sig-param">conv_a_stride=(2</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em>, <em class="sig-param">conv_a_padding=(1</em>, <em class="sig-param">0</em>, <em class="sig-param">0)</em>, <em class="sig-param">conv_a=&lt;class 'torch.nn.modules.conv.Conv3d'&gt;</em>, <em class="sig-param">conv_b_kernel_size=(1</em>, <em class="sig-param">3</em>, <em class="sig-param">3)</em>, <em class="sig-param">conv_b_stride=(1</em>, <em class="sig-param">2</em>, <em class="sig-param">2)</em>, <em class="sig-param">conv_b_padding=(0</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em>, <em class="sig-param">conv_b_num_groups=1</em>, <em class="sig-param">conv_b_dilation=(1</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em>, <em class="sig-param">conv_b=&lt;class 'torch.nn.modules.conv.Conv3d'&gt;</em>, <em class="sig-param">conv_c=&lt;class 'torch.nn.modules.conv.Conv3d'&gt;</em>, <em class="sig-param">norm=&lt;class 'torch.nn.modules.batchnorm.BatchNorm3d'&gt;</em>, <em class="sig-param">norm_eps=1e-05</em>, <em class="sig-param">norm_momentum=0.1</em>, <em class="sig-param">activation=&lt;class 'torch.nn.modules.activation.ReLU'&gt;</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/pytorchvideo/models/resnet.html#create_bottleneck_block"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pytorchvideo.models.resnet.create_bottleneck_block" title="Permalink to this definition">¶</a></dt>
<dd><p>Bottleneck block: a sequence of spatiotemporal Convolution, Normalization,
and Activations repeated in the following order:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>   Conv3d (conv_a)
          ↓
Normalization (norm_a)
          ↓
  Activation (act_a)
          ↓
   Conv3d (conv_b)
          ↓
Normalization (norm_b)
          ↓
  Activation (act_b)
          ↓
   Conv3d (conv_c)
          ↓
Normalization (norm_c)
</pre></div>
</div>
<p>Normalization examples include: BatchNorm3d and None (no normalization).
Activation examples include: ReLU, Softmax, Sigmoid, and None (no activation).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dim_in</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – input channel size to the bottleneck block.</p></li>
<li><p><strong>dim_inner</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – intermediate channel size of the bottleneck.</p></li>
<li><p><strong>dim_out</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – output channel size of the bottleneck.</p></li>
<li><p><strong>conv_a_kernel_size</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – convolutional kernel size(s) for conv_a.</p></li>
<li><p><strong>conv_a_stride</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – convolutional stride size(s) for conv_a.</p></li>
<li><p><strong>conv_a_padding</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – convolutional padding(s) for conv_a.</p></li>
<li><p><strong>conv_a</strong> (<em>callable</em>) – a callable that constructs the conv_a conv layer, examples
include nn.Conv3d, OctaveConv, etc</p></li>
<li><p><strong>conv_b_kernel_size</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – convolutional kernel size(s) for conv_b.</p></li>
<li><p><strong>conv_b_stride</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – convolutional stride size(s) for conv_b.</p></li>
<li><p><strong>conv_b_padding</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – convolutional padding(s) for conv_b.</p></li>
<li><p><strong>conv_b_num_groups</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – number of groups for groupwise convolution for
conv_b.</p></li>
<li><p><strong>conv_b_dilation</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – dilation for 3D convolution for conv_b.</p></li>
<li><p><strong>conv_b</strong> (<em>callable</em>) – a callable that constructs the conv_b conv layer, examples
include nn.Conv3d, OctaveConv, etc</p></li>
<li><p><strong>conv_c</strong> (<em>callable</em>) – a callable that constructs the conv_c conv layer, examples
include nn.Conv3d, OctaveConv, etc</p></li>
<li><p><strong>norm</strong> (<em>callable</em>) – a callable that constructs normalization layer, examples
include nn.BatchNorm3d, None (not performing normalization).</p></li>
<li><p><strong>norm_eps</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) – normalization epsilon.</p></li>
<li><p><strong>norm_momentum</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) – normalization momentum.</p></li>
<li><p><strong>activation</strong> (<em>callable</em>) – a callable that constructs activation layer, examples
include: nn.ReLU, nn.Softmax, nn.Sigmoid, and None (not performing
activation).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><em>(nn.Module)</em> – resnet bottleneck block.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.nn.modules.module.Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pytorchvideo.models.resnet.create_acoustic_bottleneck_block">
<code class="sig-prename descclassname">pytorchvideo.models.resnet.</code><code class="sig-name descname">create_acoustic_bottleneck_block</code><span class="sig-paren">(</span><em class="sig-param">*</em>, <em class="sig-param">dim_in</em>, <em class="sig-param">dim_inner</em>, <em class="sig-param">dim_out</em>, <em class="sig-param">conv_a_kernel_size=(3</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em>, <em class="sig-param">conv_a_stride=(2</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em>, <em class="sig-param">conv_a_padding=(1</em>, <em class="sig-param">0</em>, <em class="sig-param">0)</em>, <em class="sig-param">conv_a=&lt;class 'torch.nn.modules.conv.Conv3d'&gt;</em>, <em class="sig-param">conv_b_kernel_size=(1</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em>, <em class="sig-param">conv_b_stride=(1</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em>, <em class="sig-param">conv_b_padding=(0</em>, <em class="sig-param">0</em>, <em class="sig-param">0)</em>, <em class="sig-param">conv_b_num_groups=1</em>, <em class="sig-param">conv_b_dilation=(1</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em>, <em class="sig-param">conv_b=&lt;class 'torch.nn.modules.conv.Conv3d'&gt;</em>, <em class="sig-param">conv_c=&lt;class 'torch.nn.modules.conv.Conv3d'&gt;</em>, <em class="sig-param">norm=&lt;class 'torch.nn.modules.batchnorm.BatchNorm3d'&gt;</em>, <em class="sig-param">norm_eps=1e-05</em>, <em class="sig-param">norm_momentum=0.1</em>, <em class="sig-param">activation=&lt;class 'torch.nn.modules.activation.ReLU'&gt;</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/pytorchvideo/models/resnet.html#create_acoustic_bottleneck_block"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pytorchvideo.models.resnet.create_acoustic_bottleneck_block" title="Permalink to this definition">¶</a></dt>
<dd><p>Acoustic Bottleneck block: a sequence of spatiotemporal Convolution, Normalization,
and Activations repeated in the following order:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>                    Conv3d (conv_a)
                           ↓
                 Normalization (norm_a)
                           ↓
                   Activation (act_a)
                           ↓
           ---------------------------------
           ↓                               ↓
Temporal Conv3d (conv_b)        Spatial Conv3d (conv_b)
           ↓                               ↓
 Normalization (norm_b)         Normalization (norm_b)
           ↓                               ↓
   Activation (act_b)              Activation (act_b)
           ↓                               ↓
           ---------------------------------
                           ↓
                    Conv3d (conv_c)
                           ↓
                 Normalization (norm_c)
</pre></div>
</div>
<p>Normalization examples include: BatchNorm3d and None (no normalization).
Activation examples include: ReLU, Softmax, Sigmoid, and None (no activation).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dim_in</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – input channel size to the bottleneck block.</p></li>
<li><p><strong>dim_inner</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – intermediate channel size of the bottleneck.</p></li>
<li><p><strong>dim_out</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – output channel size of the bottleneck.</p></li>
<li><p><strong>conv_a_kernel_size</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – convolutional kernel size(s) for conv_a.</p></li>
<li><p><strong>conv_a_stride</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – convolutional stride size(s) for conv_a.</p></li>
<li><p><strong>conv_a_padding</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – convolutional padding(s) for conv_a.</p></li>
<li><p><strong>conv_a</strong> (<em>callable</em>) – a callable that constructs the conv_a conv layer, examples
include nn.Conv3d, OctaveConv, etc</p></li>
<li><p><strong>conv_b_kernel_size</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – convolutional kernel size(s) for conv_b.</p></li>
<li><p><strong>conv_b_stride</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – convolutional stride size(s) for conv_b.</p></li>
<li><p><strong>conv_b_padding</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – convolutional padding(s) for conv_b.</p></li>
<li><p><strong>conv_b_num_groups</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – number of groups for groupwise convolution for
conv_b.</p></li>
<li><p><strong>conv_b_dilation</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – dilation for 3D convolution for conv_b.</p></li>
<li><p><strong>conv_b</strong> (<em>callable</em>) – a callable that constructs the conv_b conv layer, examples
include nn.Conv3d, OctaveConv, etc</p></li>
<li><p><strong>conv_c</strong> (<em>callable</em>) – a callable that constructs the conv_c conv layer, examples
include nn.Conv3d, OctaveConv, etc</p></li>
<li><p><strong>norm</strong> (<em>callable</em>) – a callable that constructs normalization layer, examples
include nn.BatchNorm3d, None (not performing normalization).</p></li>
<li><p><strong>norm_eps</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) – normalization epsilon.</p></li>
<li><p><strong>norm_momentum</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) – normalization momentum.</p></li>
<li><p><strong>activation</strong> (<em>callable</em>) – a callable that constructs activation layer, examples
include: nn.ReLU, nn.Softmax, nn.Sigmoid, and None (not performing
activation).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><em>(nn.Module)</em> – resnet acoustic bottleneck block.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.nn.modules.module.Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pytorchvideo.models.resnet.create_res_block">
<code class="sig-prename descclassname">pytorchvideo.models.resnet.</code><code class="sig-name descname">create_res_block</code><span class="sig-paren">(</span><em class="sig-param">*</em>, <em class="sig-param">dim_in</em>, <em class="sig-param">dim_inner</em>, <em class="sig-param">dim_out</em>, <em class="sig-param">bottleneck</em>, <em class="sig-param">use_shortcut=False</em>, <em class="sig-param">branch_fusion=&lt;function &lt;lambda&gt;&gt;</em>, <em class="sig-param">conv_a_kernel_size=(3</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em>, <em class="sig-param">conv_a_stride=(2</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em>, <em class="sig-param">conv_a_padding=(1</em>, <em class="sig-param">0</em>, <em class="sig-param">0)</em>, <em class="sig-param">conv_a=&lt;class 'torch.nn.modules.conv.Conv3d'&gt;</em>, <em class="sig-param">conv_b_kernel_size=(1</em>, <em class="sig-param">3</em>, <em class="sig-param">3)</em>, <em class="sig-param">conv_b_stride=(1</em>, <em class="sig-param">2</em>, <em class="sig-param">2)</em>, <em class="sig-param">conv_b_padding=(0</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em>, <em class="sig-param">conv_b_num_groups=1</em>, <em class="sig-param">conv_b_dilation=(1</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em>, <em class="sig-param">conv_b=&lt;class 'torch.nn.modules.conv.Conv3d'&gt;</em>, <em class="sig-param">conv_c=&lt;class 'torch.nn.modules.conv.Conv3d'&gt;</em>, <em class="sig-param">conv_skip=&lt;class 'torch.nn.modules.conv.Conv3d'&gt;</em>, <em class="sig-param">norm=&lt;class 'torch.nn.modules.batchnorm.BatchNorm3d'&gt;</em>, <em class="sig-param">norm_eps=1e-05</em>, <em class="sig-param">norm_momentum=0.1</em>, <em class="sig-param">activation_bottleneck=&lt;class 'torch.nn.modules.activation.ReLU'&gt;</em>, <em class="sig-param">activation_block=&lt;class 'torch.nn.modules.activation.ReLU'&gt;</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/pytorchvideo/models/resnet.html#create_res_block"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pytorchvideo.models.resnet.create_res_block" title="Permalink to this definition">¶</a></dt>
<dd><p>Residual block. Performs a summation between an identity shortcut in branch1 and a
main block in branch2. When the input and output dimensions are different, a
convolution followed by a normalization will be performed.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>  Input
    |-------+
    ↓       |
  Block     |
    ↓       |
Summation ←-+
    ↓
Activation
</pre></div>
</div>
<p>Normalization examples include: BatchNorm3d and None (no normalization).
Activation examples include: ReLU, Softmax, Sigmoid, and None (no activation).
Transform examples include: BottleneckBlock.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dim_in</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – input channel size to the bottleneck block.</p></li>
<li><p><strong>dim_inner</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – intermediate channel size of the bottleneck.</p></li>
<li><p><strong>dim_out</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – output channel size of the bottleneck.</p></li>
<li><p><strong>bottleneck</strong> (<em>callable</em>) – a callable that constructs bottleneck block layer.
Examples include: create_bottleneck_block.</p></li>
<li><p><strong>use_shortcut</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – If true, use conv and norm layers in skip connection.</p></li>
<li><p><strong>branch_fusion</strong> (<em>callable</em>) – a callable that constructs summation layer.
Examples include: lambda x, y: x + y, OctaveSum.</p></li>
<li><p><strong>conv_a_kernel_size</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – convolutional kernel size(s) for conv_a.</p></li>
<li><p><strong>conv_a_stride</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – convolutional stride size(s) for conv_a.</p></li>
<li><p><strong>conv_a_padding</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – convolutional padding(s) for conv_a.</p></li>
<li><p><strong>conv_a</strong> (<em>callable</em>) – a callable that constructs the conv_a conv layer, examples
include nn.Conv3d, OctaveConv, etc</p></li>
<li><p><strong>conv_b_kernel_size</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – convolutional kernel size(s) for conv_b.</p></li>
<li><p><strong>conv_b_stride</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – convolutional stride size(s) for conv_b.</p></li>
<li><p><strong>conv_b_padding</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – convolutional padding(s) for conv_b.</p></li>
<li><p><strong>conv_b_num_groups</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – number of groups for groupwise convolution for
conv_b.</p></li>
<li><p><strong>conv_b_dilation</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – dilation for 3D convolution for conv_b.</p></li>
<li><p><strong>conv_b</strong> (<em>callable</em>) – a callable that constructs the conv_b conv layer, examples
include nn.Conv3d, OctaveConv, etc</p></li>
<li><p><strong>conv_c</strong> (<em>callable</em>) – a callable that constructs the conv_c conv layer, examples
include nn.Conv3d, OctaveConv, etc</p></li>
<li><p><strong>conv_skip</strong> (<em>callable</em>) – a callable that constructs the conv_skip conv layer,</p></li>
<li><p><strong>include nn.Conv3d</strong> (<em>examples</em>) – </p></li>
<li><p><strong>OctaveConv</strong> – </p></li>
<li><p><strong>etc</strong> – </p></li>
<li><p><strong>norm</strong> (<em>callable</em>) – a callable that constructs normalization layer. Examples
include nn.BatchNorm3d, None (not performing normalization).</p></li>
<li><p><strong>norm_eps</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) – normalization epsilon.</p></li>
<li><p><strong>norm_momentum</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) – normalization momentum.</p></li>
<li><p><strong>activation_bottleneck</strong> (<em>callable</em>) – a callable that constructs activation layer in
bottleneck. Examples include: nn.ReLU, nn.Softmax, nn.Sigmoid, and None
(not performing activation).</p></li>
<li><p><strong>activation_block</strong> (<em>callable</em>) – a callable that constructs activation layer used
at the end of the block. Examples include: nn.ReLU, nn.Softmax, nn.Sigmoid,
and None (not performing activation).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><em>(nn.Module)</em> – resnet basic block layer.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.nn.modules.module.Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pytorchvideo.models.resnet.create_res_stage">
<code class="sig-prename descclassname">pytorchvideo.models.resnet.</code><code class="sig-name descname">create_res_stage</code><span class="sig-paren">(</span><em class="sig-param">*</em>, <em class="sig-param">depth</em>, <em class="sig-param">dim_in</em>, <em class="sig-param">dim_inner</em>, <em class="sig-param">dim_out</em>, <em class="sig-param">bottleneck</em>, <em class="sig-param">conv_a_kernel_size=(3</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em>, <em class="sig-param">conv_a_stride=(2</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em>, <em class="sig-param">conv_a_padding=(1</em>, <em class="sig-param">0</em>, <em class="sig-param">0)</em>, <em class="sig-param">conv_a=&lt;class 'torch.nn.modules.conv.Conv3d'&gt;</em>, <em class="sig-param">conv_b_kernel_size=(1</em>, <em class="sig-param">3</em>, <em class="sig-param">3)</em>, <em class="sig-param">conv_b_stride=(1</em>, <em class="sig-param">2</em>, <em class="sig-param">2)</em>, <em class="sig-param">conv_b_padding=(0</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em>, <em class="sig-param">conv_b_num_groups=1</em>, <em class="sig-param">conv_b_dilation=(1</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em>, <em class="sig-param">conv_b=&lt;class 'torch.nn.modules.conv.Conv3d'&gt;</em>, <em class="sig-param">conv_c=&lt;class 'torch.nn.modules.conv.Conv3d'&gt;</em>, <em class="sig-param">norm=&lt;class 'torch.nn.modules.batchnorm.BatchNorm3d'&gt;</em>, <em class="sig-param">norm_eps=1e-05</em>, <em class="sig-param">norm_momentum=0.1</em>, <em class="sig-param">activation=&lt;class 'torch.nn.modules.activation.ReLU'&gt;</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/pytorchvideo/models/resnet.html#create_res_stage"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pytorchvideo.models.resnet.create_res_stage" title="Permalink to this definition">¶</a></dt>
<dd><p>Create Residual Stage, which composes sequential blocks that make up a ResNet. These
blocks could be, for example, Residual blocks, Non-Local layers, or
Squeeze-Excitation layers.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span> Input
    ↓
ResBlock
    ↓
    .
    .
    .
    ↓
ResBlock
</pre></div>
</div>
<p>Normalization examples include: BatchNorm3d and None (no normalization).
Activation examples include: ReLU, Softmax, Sigmoid, and None (no activation).
Bottleneck examples include: create_bottleneck_block.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>depth</strong> (<em>init</em>) – number of blocks to create.</p></li>
<li><p><strong>dim_in</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – input channel size to the bottleneck block.</p></li>
<li><p><strong>dim_inner</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – intermediate channel size of the bottleneck.</p></li>
<li><p><strong>dim_out</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – output channel size of the bottleneck.</p></li>
<li><p><strong>bottleneck</strong> (<em>callable</em>) – a callable that constructs bottleneck block layer.
Examples include: create_bottleneck_block.</p></li>
<li><p><strong>conv_a_kernel_size</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a><em> or </em><em>list of tuple</em>) – convolutional kernel size(s)
for conv_a. If conv_a_kernel_size is a tuple, use it for all blocks in
the stage. If conv_a_kernel_size is a list of tuple, the kernel sizes
will be repeated until having same length of depth in the stage. For
example, for conv_a_kernel_size = [(3, 1, 1), (1, 1, 1)], the kernel
size for the first 6 blocks would be [(3, 1, 1), (1, 1, 1), (3, 1, 1),
(1, 1, 1), (3, 1, 1)].</p></li>
<li><p><strong>conv_a_stride</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – convolutional stride size(s) for conv_a.</p></li>
<li><p><strong>conv_a_padding</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a><em> or </em><em>list of tuple</em>) – convolutional padding(s) for
conv_a. If conv_a_padding is a tuple, use it for all blocks in
the stage. If conv_a_padding is a list of tuple, the padding sizes
will be repeated until having same length of depth in the stage.</p></li>
<li><p><strong>conv_a</strong> (<em>callable</em>) – a callable that constructs the conv_a conv layer, examples
include nn.Conv3d, OctaveConv, etc</p></li>
<li><p><strong>conv_b_kernel_size</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – convolutional kernel size(s) for conv_b.</p></li>
<li><p><strong>conv_b_stride</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – convolutional stride size(s) for conv_b.</p></li>
<li><p><strong>conv_b_padding</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – convolutional padding(s) for conv_b.</p></li>
<li><p><strong>conv_b_num_groups</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – number of groups for groupwise convolution for
conv_b.</p></li>
<li><p><strong>conv_b_dilation</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – dilation for 3D convolution for conv_b.</p></li>
<li><p><strong>conv_b</strong> (<em>callable</em>) – a callable that constructs the conv_b conv layer, examples
include nn.Conv3d, OctaveConv, etc</p></li>
<li><p><strong>conv_c</strong> (<em>callable</em>) – a callable that constructs the conv_c conv layer, examples
include nn.Conv3d, OctaveConv, etc</p></li>
<li><p><strong>norm</strong> (<em>callable</em>) – a callable that constructs normalization layer. Examples
include nn.BatchNorm3d, and None (not performing normalization).</p></li>
<li><p><strong>norm_eps</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) – normalization epsilon.</p></li>
<li><p><strong>norm_momentum</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) – normalization momentum.</p></li>
<li><p><strong>activation</strong> (<em>callable</em>) – a callable that constructs activation layer. Examples
include: nn.ReLU, nn.Softmax, nn.Sigmoid, and None (not performing
activation).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><em>(nn.Module)</em> – resnet basic stage layer.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.nn.modules.module.Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pytorchvideo.models.resnet.create_resnet">
<code class="sig-prename descclassname">pytorchvideo.models.resnet.</code><code class="sig-name descname">create_resnet</code><span class="sig-paren">(</span><em class="sig-param">*</em>, <em class="sig-param">input_channel=3</em>, <em class="sig-param">model_depth=50</em>, <em class="sig-param">model_num_class=400</em>, <em class="sig-param">dropout_rate=0.5</em>, <em class="sig-param">norm=&lt;class 'torch.nn.modules.batchnorm.BatchNorm3d'&gt;</em>, <em class="sig-param">activation=&lt;class 'torch.nn.modules.activation.ReLU'&gt;</em>, <em class="sig-param">stem_dim_out=64</em>, <em class="sig-param">stem_conv_kernel_size=(3</em>, <em class="sig-param">7</em>, <em class="sig-param">7)</em>, <em class="sig-param">stem_conv_stride=(1</em>, <em class="sig-param">2</em>, <em class="sig-param">2)</em>, <em class="sig-param">stem_pool=&lt;class 'torch.nn.modules.pooling.MaxPool3d'&gt;</em>, <em class="sig-param">stem_pool_kernel_size=(1</em>, <em class="sig-param">3</em>, <em class="sig-param">3)</em>, <em class="sig-param">stem_pool_stride=(1</em>, <em class="sig-param">2</em>, <em class="sig-param">2)</em>, <em class="sig-param">stage1_pool=None</em>, <em class="sig-param">stage1_pool_kernel_size=(2</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em>, <em class="sig-param">stage_conv_a_kernel_size=((1</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em>, <em class="sig-param">(1</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em>, <em class="sig-param">(3</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em>, <em class="sig-param">(3</em>, <em class="sig-param">1</em>, <em class="sig-param">1))</em>, <em class="sig-param">stage_conv_b_kernel_size=((1</em>, <em class="sig-param">3</em>, <em class="sig-param">3)</em>, <em class="sig-param">(1</em>, <em class="sig-param">3</em>, <em class="sig-param">3)</em>, <em class="sig-param">(1</em>, <em class="sig-param">3</em>, <em class="sig-param">3)</em>, <em class="sig-param">(1</em>, <em class="sig-param">3</em>, <em class="sig-param">3))</em>, <em class="sig-param">stage_conv_b_num_groups=(1</em>, <em class="sig-param">1</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em>, <em class="sig-param">stage_conv_b_dilation=((1</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em>, <em class="sig-param">(1</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em>, <em class="sig-param">(1</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em>, <em class="sig-param">(1</em>, <em class="sig-param">1</em>, <em class="sig-param">1))</em>, <em class="sig-param">stage_spatial_stride=(1</em>, <em class="sig-param">2</em>, <em class="sig-param">2</em>, <em class="sig-param">2)</em>, <em class="sig-param">stage_temporal_stride=(1</em>, <em class="sig-param">1</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em>, <em class="sig-param">bottleneck=&lt;function create_bottleneck_block&gt;</em>, <em class="sig-param">head_pool=&lt;class 'torch.nn.modules.pooling.AvgPool3d'&gt;</em>, <em class="sig-param">head_pool_kernel_size=(4</em>, <em class="sig-param">7</em>, <em class="sig-param">7)</em>, <em class="sig-param">head_output_size=(1</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em>, <em class="sig-param">head_activation=None</em>, <em class="sig-param">head_output_with_global_average=True</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/pytorchvideo/models/resnet.html#create_resnet"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pytorchvideo.models.resnet.create_resnet" title="Permalink to this definition">¶</a></dt>
<dd><p>Build ResNet style models for video recognition. ResNet has three parts:
Stem, Stages and Head. Stem is the first Convolution layer (Conv1) with an
optional pooling layer. Stages are grouped residual blocks. There are usually
multiple stages and each stage may include multiple residual blocks. Head
may include pooling, dropout, a fully-connected layer and global spatial
temporal averaging. The three parts are assembled in the following order:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Input
  ↓
Stem
  ↓
Stage 1
  ↓
  .
  .
  .
  ↓
Stage N
  ↓
Head
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_channel</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – number of channels for the input video clip.</p></li>
<li><p><strong>model_depth</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – the depth of the resnet. Options include: 50, 101, 152.</p></li>
<li><p><strong>model_num_class</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – the number of classes for the video dataset.</p></li>
<li><p><strong>dropout_rate</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) – dropout rate.</p></li>
<li><p><strong>norm</strong> (<em>callable</em>) – a callable that constructs normalization layer.</p></li>
<li><p><strong>activation</strong> (<em>callable</em>) – a callable that constructs activation layer.</p></li>
<li><p><strong>stem_dim_out</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – output channel size to stem.</p></li>
<li><p><strong>stem_conv_kernel_size</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – convolutional kernel size(s) of stem.</p></li>
<li><p><strong>stem_conv_stride</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – convolutional stride size(s) of stem.</p></li>
<li><p><strong>stem_pool</strong> (<em>callable</em>) – a callable that constructs resnet head pooling layer.</p></li>
<li><p><strong>stem_pool_kernel_size</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – pooling kernel size(s).</p></li>
<li><p><strong>stem_pool_stride</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – pooling stride size(s).</p></li>
<li><p><strong>stage_conv_a_kernel_size</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – convolutional kernel size(s) for conv_a.</p></li>
<li><p><strong>stage_conv_b_kernel_size</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – convolutional kernel size(s) for conv_b.</p></li>
<li><p><strong>stage_conv_b_num_groups</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – number of groups for groupwise convolution
for conv_b. 1 for ResNet, and larger than 1 for ResNeXt.</p></li>
<li><p><strong>stage_conv_b_dilation</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – dilation for 3D convolution for conv_b.</p></li>
<li><p><strong>stage_spatial_stride</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – the spatial stride for each stage.</p></li>
<li><p><strong>stage_temporal_stride</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – the temporal stride for each stage.</p></li>
<li><p><strong>bottleneck</strong> (<em>callable</em>) – a callable that constructs bottleneck block layer.
Examples include: create_bottleneck_block.</p></li>
<li><p><strong>head_pool</strong> (<em>callable</em>) – a callable that constructs resnet head pooling layer.</p></li>
<li><p><strong>head_pool_kernel_size</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – the pooling kernel size.</p></li>
<li><p><strong>head_output_size</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – the size of output tensor for head.</p></li>
<li><p><strong>head_activation</strong> (<em>callable</em>) – a callable that constructs activation layer.</p></li>
<li><p><strong>head_output_with_global_average</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) – if True, perform global averaging on
the head output.</p></li>
<li><p><strong>stage1_pool</strong> (<em>Callable</em>) – </p></li>
<li><p><strong>stage1_pool_kernel_size</strong> (<em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><em>(nn.Module)</em> – basic resnet.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.nn.modules.module.Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pytorchvideo.models.resnet.create_acoustic_building_block">
<code class="sig-prename descclassname">pytorchvideo.models.resnet.</code><code class="sig-name descname">create_acoustic_building_block</code><span class="sig-paren">(</span><em class="sig-param">*</em>, <em class="sig-param">dim_in</em>, <em class="sig-param">dim_inner</em>, <em class="sig-param">dim_out</em>, <em class="sig-param">conv_a_kernel_size=None</em>, <em class="sig-param">conv_a_stride=None</em>, <em class="sig-param">conv_a_padding=None</em>, <em class="sig-param">conv_a=None</em>, <em class="sig-param">conv_b_kernel_size=(1</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em>, <em class="sig-param">conv_b_stride=(1</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em>, <em class="sig-param">conv_b_padding=(0</em>, <em class="sig-param">0</em>, <em class="sig-param">0)</em>, <em class="sig-param">conv_b_num_groups=1</em>, <em class="sig-param">conv_b_dilation=(1</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em>, <em class="sig-param">conv_b=&lt;class 'torch.nn.modules.conv.Conv3d'&gt;</em>, <em class="sig-param">conv_c=&lt;class 'torch.nn.modules.conv.Conv3d'&gt;</em>, <em class="sig-param">norm=&lt;class 'torch.nn.modules.batchnorm.BatchNorm3d'&gt;</em>, <em class="sig-param">norm_eps=1e-05</em>, <em class="sig-param">norm_momentum=0.1</em>, <em class="sig-param">activation=&lt;class 'torch.nn.modules.activation.ReLU'&gt;</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/pytorchvideo/models/resnet.html#create_acoustic_building_block"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pytorchvideo.models.resnet.create_acoustic_building_block" title="Permalink to this definition">¶</a></dt>
<dd><p>Acoustic building block: a sequence of spatiotemporal Convolution, Normalization,
and Activations repeated in the following order:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>                    Conv3d (conv_a)
                           ↓
                 Normalization (norm_a)
                           ↓
                   Activation (act_a)
                           ↓
           ---------------------------------
           ↓                               ↓
Temporal Conv3d (conv_b)        Spatial Conv3d (conv_b)
           ↓                               ↓
 Normalization (norm_b)         Normalization (norm_b)
           ↓                               ↓
   Activation (act_b)              Activation (act_b)
           ↓                               ↓
           ---------------------------------
                           ↓
                    Conv3d (conv_c)
                           ↓
                 Normalization (norm_c)
</pre></div>
</div>
<p>Normalization examples include: BatchNorm3d and None (no normalization).
Activation examples include: ReLU, Softmax, Sigmoid, and None (no activation).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dim_in</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – input channel size to the bottleneck block.</p></li>
<li><p><strong>dim_inner</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – intermediate channel size of the bottleneck.</p></li>
<li><p><strong>dim_out</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – output channel size of the bottleneck.</p></li>
<li><p><strong>conv_a_kernel_size</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – convolutional kernel size(s) for conv_a.</p></li>
<li><p><strong>conv_a_stride</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – convolutional stride size(s) for conv_a.</p></li>
<li><p><strong>conv_a_padding</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – convolutional padding(s) for conv_a.</p></li>
<li><p><strong>conv_a</strong> (<em>callable</em>) – a callable that constructs the conv_a conv layer, examples
include nn.Conv3d, OctaveConv, etc</p></li>
<li><p><strong>conv_b_kernel_size</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – convolutional kernel size(s) for conv_b.</p></li>
<li><p><strong>conv_b_stride</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – convolutional stride size(s) for conv_b.</p></li>
<li><p><strong>conv_b_padding</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – convolutional padding(s) for conv_b.</p></li>
<li><p><strong>conv_b_num_groups</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – number of groups for groupwise convolution for
conv_b.</p></li>
<li><p><strong>conv_b_dilation</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – dilation for 3D convolution for conv_b.</p></li>
<li><p><strong>conv_b</strong> (<em>callable</em>) – a callable that constructs the conv_b conv layer, examples
include nn.Conv3d, OctaveConv, etc</p></li>
<li><p><strong>conv_c</strong> (<em>callable</em>) – a callable that constructs the conv_c conv layer, examples
include nn.Conv3d, OctaveConv, etc</p></li>
<li><p><strong>norm</strong> (<em>callable</em>) – a callable that constructs normalization layer, examples
include nn.BatchNorm3d, None (not performing normalization).</p></li>
<li><p><strong>norm_eps</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) – normalization epsilon.</p></li>
<li><p><strong>norm_momentum</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) – normalization momentum.</p></li>
<li><p><strong>activation</strong> (<em>callable</em>) – a callable that constructs activation layer, examples
include: nn.ReLU, nn.Softmax, nn.Sigmoid, and None (not performing
activation).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><em>(nn.Module)</em> – resnet acoustic bottleneck block.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.nn.modules.module.Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="pytorchvideo.models.resnet.create_acoustic_resnet">
<code class="sig-prename descclassname">pytorchvideo.models.resnet.</code><code class="sig-name descname">create_acoustic_resnet</code><span class="sig-paren">(</span><em class="sig-param">*</em>, <em class="sig-param">input_channel=2</em>, <em class="sig-param">model_depth=50</em>, <em class="sig-param">model_num_class=400</em>, <em class="sig-param">dropout_rate=0.5</em>, <em class="sig-param">norm=&lt;class 'torch.nn.modules.batchnorm.BatchNorm3d'&gt;</em>, <em class="sig-param">activation=&lt;class 'torch.nn.modules.activation.ReLU'&gt;</em>, <em class="sig-param">stem_dim_out=64</em>, <em class="sig-param">stem_conv_kernel_size=(9</em>, <em class="sig-param">9</em>, <em class="sig-param">9)</em>, <em class="sig-param">stem_conv_stride=(1</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em>, <em class="sig-param">stem_conv_padding=(4</em>, <em class="sig-param">4</em>, <em class="sig-param">4)</em>, <em class="sig-param">stem_pool=&lt;class 'torch.nn.modules.pooling.MaxPool3d'&gt;</em>, <em class="sig-param">stem_pool_kernel_size=(1</em>, <em class="sig-param">3</em>, <em class="sig-param">3)</em>, <em class="sig-param">stem_pool_stride=(1</em>, <em class="sig-param">2</em>, <em class="sig-param">2)</em>, <em class="sig-param">stem=&lt;function create_acoustic_res_basic_stem&gt;</em>, <em class="sig-param">stage_conv_a_kernel_size=(3</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em>, <em class="sig-param">stage_conv_a_padding=(1</em>, <em class="sig-param">0</em>, <em class="sig-param">0)</em>, <em class="sig-param">stage_conv_b_kernel_size=(1</em>, <em class="sig-param">3</em>, <em class="sig-param">3)</em>, <em class="sig-param">stage_conv_b_padding=(0</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em>, <em class="sig-param">stage_conv_b_num_groups=1</em>, <em class="sig-param">stage_conv_b_dilation=(1</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em>, <em class="sig-param">stage_spatial_stride=(1</em>, <em class="sig-param">2</em>, <em class="sig-param">2</em>, <em class="sig-param">2)</em>, <em class="sig-param">stage_temporal_stride=(1</em>, <em class="sig-param">2</em>, <em class="sig-param">2</em>, <em class="sig-param">2)</em>, <em class="sig-param">bottleneck=(&lt;function create_acoustic_bottleneck_block&gt;</em>, <em class="sig-param">&lt;function create_acoustic_bottleneck_block&gt;</em>, <em class="sig-param">&lt;function create_bottleneck_block&gt;</em>, <em class="sig-param">&lt;function create_bottleneck_block&gt;)</em>, <em class="sig-param">head_pool=&lt;class 'torch.nn.modules.pooling.AvgPool3d'&gt;</em>, <em class="sig-param">head_output_size=(1</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em>, <em class="sig-param">head_activation=&lt;class 'torch.nn.modules.activation.Softmax'&gt;</em>, <em class="sig-param">head_pool_kernel_size=(1</em>, <em class="sig-param">1</em>, <em class="sig-param">1)</em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/pytorchvideo/models/resnet.html#create_acoustic_resnet"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pytorchvideo.models.resnet.create_acoustic_resnet" title="Permalink to this definition">¶</a></dt>
<dd><p>Build ResNet style models for acoustic recognition. ResNet has three parts:
Stem, Stages and Head. The three parts are assembled in the following order:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Input
  ↓
Stem
  ↓
Stage 1
  ↓
  .
  .
  .
  ↓
Stage N
  ↓
Head
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_channel</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – number of channels for the input video clip.</p></li>
<li><p><strong>input_clip_length</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – length of the input video clip.</p></li>
<li><p><strong>input_crop_size</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – spatial resolution of the input video clip.</p></li>
<li><p><strong>model_depth</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – the depth of the resnet.</p></li>
<li><p><strong>model_num_class</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – the number of classes for the video dataset.</p></li>
<li><p><strong>dropout_rate</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) – dropout rate.</p></li>
<li><p><strong>norm</strong> (<em>callable</em>) – a callable that constructs normalization layer.</p></li>
<li><p><strong>activation</strong> (<em>callable</em>) – a callable that constructs activation layer.</p></li>
<li><p><strong>stem_dim_out</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – output channel size to stem.</p></li>
<li><p><strong>stem_conv_kernel_size</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – convolutional kernel size(s) of stem.</p></li>
<li><p><strong>stem_conv_stride</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – convolutional stride size(s) of stem.</p></li>
<li><p><strong>stem_pool</strong> (<em>callable</em>) – a callable that constructs resnet head pooling layer.</p></li>
<li><p><strong>stem_pool_kernel_size</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – pooling kernel size(s).</p></li>
<li><p><strong>stem_pool_stride</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – pooling stride size(s).</p></li>
<li><p><strong>stem</strong> (<em>callable</em>) – a callable that constructs stem layer.
Examples include: create_res_video_stem.</p></li>
<li><p><strong>stage_conv_a_kernel_size</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – convolutional kernel size(s) for conv_a.</p></li>
<li><p><strong>stage_conv_b_kernel_size</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – convolutional kernel size(s) for conv_b.</p></li>
<li><p><strong>stage_conv_b_num_groups</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) – number of groups for groupwise convolution
for conv_b. 1 for ResNet, and larger than 1 for ResNeXt.</p></li>
<li><p><strong>stage_conv_b_dilation</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – dilation for 3D convolution for conv_b.</p></li>
<li><p><strong>stage_spatial_stride</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – the spatial stride for each stage.</p></li>
<li><p><strong>stage_temporal_stride</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – the temporal stride for each stage.</p></li>
<li><p><strong>bottleneck</strong> (<em>callable</em>) – a callable that constructs bottleneck block
layer.
Examples include: create_bottleneck_block.</p></li>
<li><p><strong>head_pool</strong> (<em>callable</em>) – a callable that constructs resnet head pooling layer.</p></li>
<li><p><strong>head_output_size</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#tuple" title="(in Python v3.6)"><em>tuple</em></a>) – the size of output tensor for head.</p></li>
<li><p><strong>head_activation</strong> (<em>callable</em>) – a callable that constructs activation layer.</p></li>
<li><p><strong>stem_conv_padding</strong> (<em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – </p></li>
<li><p><strong>stage_conv_a_padding</strong> (<em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – </p></li>
<li><p><strong>stage_conv_b_padding</strong> (<em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – </p></li>
<li><p><strong>head_pool_kernel_size</strong> (<em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3.6/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em>]</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p><em>(nn.Module)</em> –</p>
<dl class="simple">
<dt>acoustic resnet that takes audio inputs in log-mel-spectrogram of</dt><dd><p>shape B x 1 x 1 x T x F.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>torch.nn.modules.module.Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt id="pytorchvideo.models.resnet.ResBlock">
<em class="property">class </em><code class="sig-prename descclassname">pytorchvideo.models.resnet.</code><code class="sig-name descname">ResBlock</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">branch1_conv</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">branch1_norm</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">branch2</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">activation</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">branch_fusion</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/pytorchvideo/models/resnet.html#ResBlock"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pytorchvideo.models.resnet.ResBlock" title="Permalink to this definition">¶</a></dt>
<dd><p>Residual block. Performs a summation between an identity shortcut in branch1 and a
main block in branch2. When the input and output dimensions are different, a
convolution followed by a normalization will be performed.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>  Input
    |-------+
    ↓       |
  Block     |
    ↓       |
Summation ←-+
    ↓
Activation
</pre></div>
</div>
<p>The builder can be found in <cite>create_res_block</cite>.</p>
<dl class="py method">
<dt id="pytorchvideo.models.resnet.ResBlock.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">branch1_conv</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">branch1_norm</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">branch2</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">activation</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">branch_fusion</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/pytorchvideo/models/resnet.html#ResBlock.__init__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pytorchvideo.models.resnet.ResBlock.__init__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>branch1_conv</strong> (<em>torch.nn.modules</em>) – convolutional module in branch1.</p></li>
<li><p><strong>branch1_norm</strong> (<em>torch.nn.modules</em>) – normalization module in branch1.</p></li>
<li><p><strong>branch2</strong> (<em>torch.nn.modules</em>) – bottleneck block module in branch2.</p></li>
<li><p><strong>activation</strong> (<em>torch.nn.modules</em>) – activation module.</p></li>
<li><p><strong>branch_fusion</strong> (<em>Callable</em>) – (Callable): A callable or layer that combines branch1
and branch2.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>torch.nn.modules.module.Module</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="pytorchvideo.models.resnet.SeparableBottleneckBlock">
<em class="property">class </em><code class="sig-prename descclassname">pytorchvideo.models.resnet.</code><code class="sig-name descname">SeparableBottleneckBlock</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">conv_a</span></em>, <em class="sig-param"><span class="n">norm_a</span></em>, <em class="sig-param"><span class="n">act_a</span></em>, <em class="sig-param"><span class="n">conv_b</span></em>, <em class="sig-param"><span class="n">norm_b</span></em>, <em class="sig-param"><span class="n">act_b</span></em>, <em class="sig-param"><span class="n">conv_c</span></em>, <em class="sig-param"><span class="n">norm_c</span></em>, <em class="sig-param"><span class="n">reduce_method</span><span class="o">=</span><span class="default_value">'sum'</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/pytorchvideo/models/resnet.html#SeparableBottleneckBlock"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pytorchvideo.models.resnet.SeparableBottleneckBlock" title="Permalink to this definition">¶</a></dt>
<dd><p>Separable Bottleneck block: a sequence of spatiotemporal Convolution, Normalization,
and Activations repeated in the following order. Requires a tuple of models to be
provided to conv_b, norm_b, act_b to perform Convolution, Normalization, and
Activations in parallel Separably.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>      Conv3d (conv_a)
             ↓
   Normalization (norm_a)
             ↓
     Activation (act_a)
             ↓
   Conv3d(s) (conv_b), ...
           ↓ (↓)
Normalization(s) (norm_b), ...
           ↓ (↓)
   Activation(s) (act_b), ...
           ↓ (↓)
    Reduce (sum or cat)
             ↓
      Conv3d (conv_c)
             ↓
   Normalization (norm_c)
</pre></div>
</div>
<dl class="py method">
<dt id="pytorchvideo.models.resnet.SeparableBottleneckBlock.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">conv_a</span></em>, <em class="sig-param"><span class="n">norm_a</span></em>, <em class="sig-param"><span class="n">act_a</span></em>, <em class="sig-param"><span class="n">conv_b</span></em>, <em class="sig-param"><span class="n">norm_b</span></em>, <em class="sig-param"><span class="n">act_b</span></em>, <em class="sig-param"><span class="n">conv_c</span></em>, <em class="sig-param"><span class="n">norm_c</span></em>, <em class="sig-param"><span class="n">reduce_method</span><span class="o">=</span><span class="default_value">'sum'</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/pytorchvideo/models/resnet.html#SeparableBottleneckBlock.__init__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pytorchvideo.models.resnet.SeparableBottleneckBlock.__init__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>conv_a</strong> (<em>torch.nn.modules</em>) – convolutional module.</p></li>
<li><p><strong>norm_a</strong> (<em>torch.nn.modules</em>) – normalization module.</p></li>
<li><p><strong>act_a</strong> (<em>torch.nn.modules</em>) – activation module.</p></li>
<li><p><strong>conv_b</strong> (<em>torch.nn.modules_list</em>) – convolutional module(s).</p></li>
<li><p><strong>norm_b</strong> (<em>torch.nn.modules_list</em>) – normalization module(s).</p></li>
<li><p><strong>act_b</strong> (<em>torch.nn.modules_list</em>) – activation module(s).</p></li>
<li><p><strong>conv_c</strong> (<em>torch.nn.modules</em>) – convolutional module.</p></li>
<li><p><strong>norm_c</strong> (<em>torch.nn.modules</em>) – normalization module.</p></li>
<li><p><strong>reduce_method</strong> (<a class="reference external" href="https://docs.python.org/3.6/library/stdtypes.html#str" title="(in Python v3.6)"><em>str</em></a>) – if multiple conv_b is used, reduce the output with
<cite>sum</cite>, or <cite>cat</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/constants.html#None" title="(in Python v3.6)">None</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="pytorchvideo.models.resnet.BottleneckBlock">
<em class="property">class </em><code class="sig-prename descclassname">pytorchvideo.models.resnet.</code><code class="sig-name descname">BottleneckBlock</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">conv_a</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">norm_a</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">act_a</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">conv_b</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">norm_b</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">act_b</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">conv_c</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">norm_c</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/pytorchvideo/models/resnet.html#BottleneckBlock"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pytorchvideo.models.resnet.BottleneckBlock" title="Permalink to this definition">¶</a></dt>
<dd><p>Bottleneck block: a sequence of spatiotemporal Convolution, Normalization,
and Activations repeated in the following order:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>   Conv3d (conv_a)
          ↓
Normalization (norm_a)
          ↓
  Activation (act_a)
          ↓
   Conv3d (conv_b)
          ↓
Normalization (norm_b)
          ↓
  Activation (act_b)
          ↓
   Conv3d (conv_c)
          ↓
Normalization (norm_c)
</pre></div>
</div>
<p>The builder can be found in <cite>create_bottleneck_block</cite>.</p>
<dl class="py method">
<dt id="pytorchvideo.models.resnet.BottleneckBlock.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">conv_a</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">norm_a</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">act_a</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">conv_b</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">norm_b</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">act_b</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">conv_c</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">norm_c</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/pytorchvideo/models/resnet.html#BottleneckBlock.__init__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pytorchvideo.models.resnet.BottleneckBlock.__init__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>conv_a</strong> (<em>torch.nn.modules</em>) – convolutional module.</p></li>
<li><p><strong>norm_a</strong> (<em>torch.nn.modules</em>) – normalization module.</p></li>
<li><p><strong>act_a</strong> (<em>torch.nn.modules</em>) – activation module.</p></li>
<li><p><strong>conv_b</strong> (<em>torch.nn.modules</em>) – convolutional module.</p></li>
<li><p><strong>norm_b</strong> (<em>torch.nn.modules</em>) – normalization module.</p></li>
<li><p><strong>act_b</strong> (<em>torch.nn.modules</em>) – activation module.</p></li>
<li><p><strong>conv_c</strong> (<em>torch.nn.modules</em>) – convolutional module.</p></li>
<li><p><strong>norm_c</strong> (<em>torch.nn.modules</em>) – normalization module.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3.6/library/constants.html#None" title="(in Python v3.6)">None</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="pytorchvideo.models.resnet.ResStage">
<em class="property">class </em><code class="sig-prename descclassname">pytorchvideo.models.resnet.</code><code class="sig-name descname">ResStage</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">res_blocks</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/pytorchvideo/models/resnet.html#ResStage"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pytorchvideo.models.resnet.ResStage" title="Permalink to this definition">¶</a></dt>
<dd><p>ResStage composes sequential blocks that make up a ResNet. These blocks could be,
for example, Residual blocks, Non-Local layers, or Squeeze-Excitation layers.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span> Input
    ↓
ResBlock
    ↓
    .
    .
    .
    ↓
ResBlock
</pre></div>
</div>
<p>The builder can be found in <cite>create_res_stage</cite>.</p>
<dl class="py method">
<dt id="pytorchvideo.models.resnet.ResStage.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">res_blocks</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/pytorchvideo/models/resnet.html#ResStage.__init__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pytorchvideo.models.resnet.ResStage.__init__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>res_blocks</strong> (<em>torch.nn.module_list</em>) – ResBlock module(s).</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>torch.nn.modules.module.Module</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>


             </article>
             
            </div>
            <!-- <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="net.html" class="btn btn-neutral float-right" title="pytorchvideo.models.net" accesskey="n" rel="next">Next <img src="../../_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
        <a href="index.html" class="btn btn-neutral" title="Models API" accesskey="p" rel="prev"><img src="../../_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2021, PyTorchVideo contributors.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>
 -->
          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">pytorchvideo.models.resnet</a></li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
         <script src="../../_static/jquery.js"></script>
         <script src="../../_static/underscore.js"></script>
         <script src="../../_static/doctools.js"></script>
         <script src="../../_static/language_data.js"></script>
     

  

  <script type="text/javascript" src="../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->


  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorchvideo.org" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorchvideo.org">Home</a>
          </li>
          <li>
            <a href="https://pytorchvideo.org/docs/tutorial_overview">Tutorials</a>
          </li>
          <li>
            <a href="https://github.com/facebookresearch/pytorchvideo/">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>
  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>