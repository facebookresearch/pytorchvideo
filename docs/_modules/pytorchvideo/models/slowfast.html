


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>pytorchvideo.models.slowfast &mdash; PyTorchVideo  documentation</title>
  

  
  
    <link rel="shortcut icon" href="../../../_static/favicon.png"/>
  
  
  
    <link rel="canonical" href="https://pytorchvideo.org/docs/_modules/pytorchvideo/models/slowfast.html"/>
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" /> -->
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 

  
  <script src="../../../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorchvideo.org" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorchvideo.org">Home</a>
          </li>
          <li>
            <a href="https://pytorchvideo.org/docs/tutorial_overview">Tutorials</a>
          </li>
          <li>
            <a href="https://github.com/facebookresearch/pytorchvideo/">Github</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>


<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../docs/models.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../docs/model_zoo.html">Model Zoo and Benchmarks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/models/index.html">Models API</a></li>
</ul>
<p class="caption"><span class="caption-text">Data</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../docs/data.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../docs/data_preparation.html">Data Preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/data/index.html">Data API</a></li>
</ul>
<p class="caption"><span class="caption-text">Transforms</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../docs/transforms.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/transforms/index.html">Transforms API</a></li>
</ul>
<p class="caption"><span class="caption-text">Layers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../docs/layers.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/layers/index.html">Layers API</a></li>
</ul>
<p class="caption"><span class="caption-text">Accelerator</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../docs/accelerator.html">Overview</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="../../index.html">Module code</a> &gt;</li>
        
      <li>pytorchvideo.models.slowfast</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <h1>Source code for pytorchvideo.models.slowfast</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.</span>

<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">pytorchvideo.layers.utils</span> <span class="kn">import</span> <span class="n">set_attributes</span>
<span class="kn">from</span> <span class="nn">pytorchvideo.models.head</span> <span class="kn">import</span> <span class="n">create_res_basic_head</span>
<span class="kn">from</span> <span class="nn">pytorchvideo.models.net</span> <span class="kn">import</span> <span class="n">MultiPathWayWithFuse</span><span class="p">,</span> <span class="n">Net</span>
<span class="kn">from</span> <span class="nn">pytorchvideo.models.resnet</span> <span class="kn">import</span> <span class="n">create_bottleneck_block</span><span class="p">,</span> <span class="n">create_res_stage</span>
<span class="kn">from</span> <span class="nn">pytorchvideo.models.stem</span> <span class="kn">import</span> <span class="n">create_res_basic_stem</span>


<div class="viewcode-block" id="create_slowfast"><a class="viewcode-back" href="../../../api/models/slowfast.html#pytorchvideo.models.slowfast.create_slowfast">[docs]</a><span class="k">def</span> <span class="nf">create_slowfast</span><span class="p">(</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="c1"># SlowFast configs.</span>
    <span class="n">slowfast_channel_reduction_ratio</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">8</span><span class="p">,),</span>
    <span class="n">slowfast_conv_channel_fusion_ratio</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="n">slowfast_fusion_conv_kernel_size</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
        <span class="mi">7</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
    <span class="p">),</span>  <span class="c1"># deprecated, use fusion_builder</span>
    <span class="n">slowfast_fusion_conv_stride</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
        <span class="mi">4</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
    <span class="p">),</span>  <span class="c1"># deprecated, use fusion_builder</span>
    <span class="n">fusion_builder</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[</span>
        <span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span>
    <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># Args: fusion_dim_in, stage_idx</span>
    <span class="c1"># Input clip configs.</span>
    <span class="n">input_channels</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
    <span class="c1"># Model configs.</span>
    <span class="n">model_depth</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span>
    <span class="n">model_num_class</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">400</span><span class="p">,</span>
    <span class="n">dropout_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
    <span class="c1"># Normalization configs.</span>
    <span class="n">norm</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm3d</span><span class="p">,</span>
    <span class="c1"># Activation configs.</span>
    <span class="n">activation</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span>
    <span class="c1"># Stem configs.</span>
    <span class="n">stem_function</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">create_res_basic_stem</span><span class="p">,</span>
        <span class="n">create_res_basic_stem</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="n">stem_dim_outs</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span>
    <span class="n">stem_conv_kernel_sizes</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">)),</span>
    <span class="n">stem_conv_strides</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span>
    <span class="n">stem_pool</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Callable</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Callable</span><span class="p">]]</span> <span class="o">=</span> <span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">MaxPool3d</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool3d</span><span class="p">),</span>
    <span class="n">stem_pool_kernel_sizes</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)),</span>
    <span class="n">stem_pool_strides</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span>
    <span class="c1"># Stage configs.</span>
    <span class="n">stage_conv_a_kernel_sizes</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]]]</span> <span class="o">=</span> <span class="p">(</span>
        <span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
        <span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
    <span class="p">),</span>
    <span class="n">stage_conv_b_kernel_sizes</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]]]</span> <span class="o">=</span> <span class="p">(</span>
        <span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)),</span>
        <span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)),</span>
    <span class="p">),</span>
    <span class="n">stage_conv_b_num_groups</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
    <span class="n">stage_conv_b_dilations</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]]]</span> <span class="o">=</span> <span class="p">(</span>
        <span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
        <span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
    <span class="p">),</span>
    <span class="n">stage_spatial_strides</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span>
    <span class="n">stage_temporal_strides</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
    <span class="n">bottleneck</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Callable</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Callable</span><span class="p">]]]</span> <span class="o">=</span> <span class="p">(</span>
        <span class="p">(</span>
            <span class="n">create_bottleneck_block</span><span class="p">,</span>
            <span class="n">create_bottleneck_block</span><span class="p">,</span>
            <span class="n">create_bottleneck_block</span><span class="p">,</span>
            <span class="n">create_bottleneck_block</span><span class="p">,</span>
        <span class="p">),</span>
        <span class="p">(</span>
            <span class="n">create_bottleneck_block</span><span class="p">,</span>
            <span class="n">create_bottleneck_block</span><span class="p">,</span>
            <span class="n">create_bottleneck_block</span><span class="p">,</span>
            <span class="n">create_bottleneck_block</span><span class="p">,</span>
        <span class="p">),</span>
    <span class="p">),</span>
    <span class="c1"># Head configs.</span>
    <span class="n">head_pool</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AvgPool3d</span><span class="p">,</span>
    <span class="n">head_pool_kernel_sizes</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="p">((</span><span class="mi">8</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">)),</span>
    <span class="n">head_output_size</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
    <span class="n">head_activation</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">head_output_with_global_average</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Build SlowFast model for video recognition, SlowFast model involves a Slow pathway,</span>
<span class="sd">    operating at low frame rate, to capture spatial semantics, and a Fast pathway,</span>
<span class="sd">    operating at high frame rate, to capture motion at fine temporal resolution. The</span>
<span class="sd">    Fast pathway can be made very lightweight by reducing its channel capacity, yet can</span>
<span class="sd">    learn useful temporal information for video recognition. Details can be found from</span>
<span class="sd">    the paper:</span>

<span class="sd">    Christoph Feichtenhofer, Haoqi Fan, Jitendra Malik, and Kaiming He.</span>
<span class="sd">    &quot;SlowFast networks for video recognition.&quot;</span>
<span class="sd">    https://arxiv.org/pdf/1812.03982.pdf</span>

<span class="sd">    ::</span>

<span class="sd">                             Slow Input  Fast Input</span>
<span class="sd">                                  ↓           ↓</span>
<span class="sd">                                 Stem       Stem</span>
<span class="sd">                                  ↓ ⭠ Fusion- ↓</span>
<span class="sd">                               Stage 1     Stage 1</span>
<span class="sd">                                  ↓ ⭠ Fusion- ↓</span>
<span class="sd">                                  .           .</span>
<span class="sd">                                  ↓           ↓</span>
<span class="sd">                               Stage N     Stage N</span>
<span class="sd">                                  ↓ ⭠ Fusion- ↓</span>
<span class="sd">                                         ↓</span>
<span class="sd">                                       Head</span>

<span class="sd">    Args:</span>
<span class="sd">        slowfast_channel_reduction_ratio (int): Corresponds to the inverse of the channel</span>
<span class="sd">            reduction ratio, $\beta$ between the Slow and Fast pathways.</span>
<span class="sd">        slowfast_conv_channel_fusion_ratio (int): Ratio of channel dimensions</span>
<span class="sd">            between the Slow and Fast pathways.</span>
<span class="sd">        DEPRECATED slowfast_fusion_conv_kernel_size (tuple): the convolutional kernel</span>
<span class="sd">            size used for fusion.</span>
<span class="sd">        DEPRECATED slowfast_fusion_conv_stride (tuple): the convolutional stride size</span>
<span class="sd">            used for fusion.</span>
<span class="sd">        fusion_builder (Callable[[int, int], nn.Module]): Builder function for generating</span>
<span class="sd">            the fusion modules based on stage dimension and index</span>

<span class="sd">        input_channels (tuple): number of channels for the input video clip.</span>

<span class="sd">        model_depth (int): the depth of the resnet.</span>
<span class="sd">        model_num_class (int): the number of classes for the video dataset.</span>
<span class="sd">        dropout_rate (float): dropout rate.</span>

<span class="sd">        norm (callable): a callable that constructs normalization layer.</span>

<span class="sd">        activation (callable): a callable that constructs activation layer.</span>

<span class="sd">        stem_function (Tuple[Callable]): a callable that constructs stem layer.</span>
<span class="sd">            Examples include create_res_basic_stem. Indexed by pathway</span>
<span class="sd">        stem_dim_outs (tuple): output channel size to stem.</span>
<span class="sd">        stem_conv_kernel_sizes (tuple): convolutional kernel size(s) of stem.</span>
<span class="sd">        stem_conv_strides (tuple): convolutional stride size(s) of stem.</span>
<span class="sd">        stem_pool (Tuple[Callable]): a callable that constructs resnet head pooling layer.</span>
<span class="sd">            Indexed by pathway</span>
<span class="sd">        stem_pool_kernel_sizes (tuple): pooling kernel size(s).</span>
<span class="sd">        stem_pool_strides (tuple): pooling stride size(s).</span>

<span class="sd">        stage_conv_a_kernel_sizes (tuple): convolutional kernel size(s) for conv_a.</span>
<span class="sd">        stage_conv_b_kernel_sizes (tuple): convolutional kernel size(s) for conv_b.</span>
<span class="sd">        stage_conv_b_num_groups (tuple): number of groups for groupwise convolution</span>
<span class="sd">            for conv_b. 1 for ResNet, and larger than 1 for ResNeXt.</span>
<span class="sd">        stage_conv_b_dilations (tuple): dilation for 3D convolution for conv_b.</span>
<span class="sd">        stage_spatial_strides (tuple): the spatial stride for each stage.</span>
<span class="sd">        stage_temporal_strides (tuple): the temporal stride for each stage.</span>
<span class="sd">        bottleneck (Tuple[Tuple[Callable]]): a callable that constructs bottleneck</span>
<span class="sd">            block layer. Examples include: create_bottleneck_block.</span>
<span class="sd">            Indexed by pathway and stage index</span>

<span class="sd">        head_pool (callable): a callable that constructs resnet head pooling layer.</span>
<span class="sd">        head_output_sizes (tuple): the size of output tensor for head.</span>
<span class="sd">        head_activation (callable): a callable that constructs activation layer.</span>
<span class="sd">        head_output_with_global_average (bool): if True, perform global averaging on</span>
<span class="sd">            the head output.</span>
<span class="sd">    Returns:</span>
<span class="sd">        (nn.Module): SlowFast model.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Number of blocks for different stages given the model depth.</span>
    <span class="n">_num_pathway</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_channels</span><span class="p">)</span>
    <span class="n">_MODEL_STAGE_DEPTH</span> <span class="o">=</span> <span class="p">{</span>
        <span class="mi">18</span><span class="p">:</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
        <span class="mi">50</span><span class="p">:</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
        <span class="mi">101</span><span class="p">:</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">23</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
        <span class="mi">152</span><span class="p">:</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">36</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
    <span class="p">}</span>
    <span class="k">assert</span> <span class="p">(</span>
        <span class="n">model_depth</span> <span class="ow">in</span> <span class="n">_MODEL_STAGE_DEPTH</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_depth</span><span class="si">}</span><span class="s2"> is not in </span><span class="si">{</span><span class="n">_MODEL_STAGE_DEPTH</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="n">stage_depths</span> <span class="o">=</span> <span class="n">_MODEL_STAGE_DEPTH</span><span class="p">[</span><span class="n">model_depth</span><span class="p">]</span>

    <span class="c1"># Fix up inputs</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">slowfast_channel_reduction_ratio</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">slowfast_channel_reduction_ratio</span> <span class="o">=</span> <span class="p">(</span><span class="n">slowfast_channel_reduction_ratio</span><span class="p">,)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">stem_pool</span><span class="p">,</span> <span class="n">Callable</span><span class="p">):</span>
        <span class="n">stem_pool</span> <span class="o">=</span> <span class="p">(</span><span class="n">stem_pool</span><span class="p">,)</span> <span class="o">*</span> <span class="n">_num_pathway</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">bottleneck</span><span class="p">,</span> <span class="n">Callable</span><span class="p">):</span>
        <span class="n">bottleneck</span> <span class="o">=</span> <span class="p">(</span><span class="n">bottleneck</span><span class="p">,)</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">stage_depths</span><span class="p">)</span>
        <span class="n">bottleneck</span> <span class="o">=</span> <span class="p">(</span><span class="n">bottleneck</span><span class="p">,)</span> <span class="o">*</span> <span class="n">_num_pathway</span>
    <span class="k">if</span> <span class="n">fusion_builder</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">fusion_builder</span> <span class="o">=</span> <span class="n">FastToSlowFusionBuilder</span><span class="p">(</span>
            <span class="n">slowfast_channel_reduction_ratio</span><span class="o">=</span><span class="n">slowfast_channel_reduction_ratio</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
            <span class="n">conv_fusion_channel_ratio</span><span class="o">=</span><span class="n">slowfast_conv_channel_fusion_ratio</span><span class="p">,</span>
            <span class="n">conv_kernel_size</span><span class="o">=</span><span class="n">slowfast_fusion_conv_kernel_size</span><span class="p">,</span>
            <span class="n">conv_stride</span><span class="o">=</span><span class="n">slowfast_fusion_conv_stride</span><span class="p">,</span>
            <span class="n">norm</span><span class="o">=</span><span class="n">norm</span><span class="p">,</span>
            <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">,</span>
            <span class="n">max_stage_idx</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">stage_depths</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span>
        <span class="p">)</span><span class="o">.</span><span class="n">create_module</span>

    <span class="c1"># Build stem blocks.</span>
    <span class="n">stems</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">pathway_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">_num_pathway</span><span class="p">):</span>
        <span class="n">stems</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">stem_function</span><span class="p">[</span><span class="n">pathway_idx</span><span class="p">](</span>
                <span class="n">in_channels</span><span class="o">=</span><span class="n">input_channels</span><span class="p">[</span><span class="n">pathway_idx</span><span class="p">],</span>
                <span class="n">out_channels</span><span class="o">=</span><span class="n">stem_dim_outs</span><span class="p">[</span><span class="n">pathway_idx</span><span class="p">],</span>
                <span class="n">conv_kernel_size</span><span class="o">=</span><span class="n">stem_conv_kernel_sizes</span><span class="p">[</span><span class="n">pathway_idx</span><span class="p">],</span>
                <span class="n">conv_stride</span><span class="o">=</span><span class="n">stem_conv_strides</span><span class="p">[</span><span class="n">pathway_idx</span><span class="p">],</span>
                <span class="n">conv_padding</span><span class="o">=</span><span class="p">[</span>
                    <span class="n">size</span> <span class="o">//</span> <span class="mi">2</span> <span class="k">for</span> <span class="n">size</span> <span class="ow">in</span> <span class="n">stem_conv_kernel_sizes</span><span class="p">[</span><span class="n">pathway_idx</span><span class="p">]</span>
                <span class="p">],</span>
                <span class="n">pool</span><span class="o">=</span><span class="n">stem_pool</span><span class="p">[</span><span class="n">pathway_idx</span><span class="p">],</span>
                <span class="n">pool_kernel_size</span><span class="o">=</span><span class="n">stem_pool_kernel_sizes</span><span class="p">[</span><span class="n">pathway_idx</span><span class="p">],</span>
                <span class="n">pool_stride</span><span class="o">=</span><span class="n">stem_pool_strides</span><span class="p">[</span><span class="n">pathway_idx</span><span class="p">],</span>
                <span class="n">pool_padding</span><span class="o">=</span><span class="p">[</span>
                    <span class="n">size</span> <span class="o">//</span> <span class="mi">2</span> <span class="k">for</span> <span class="n">size</span> <span class="ow">in</span> <span class="n">stem_pool_kernel_sizes</span><span class="p">[</span><span class="n">pathway_idx</span><span class="p">]</span>
                <span class="p">],</span>
                <span class="n">norm</span><span class="o">=</span><span class="n">norm</span><span class="p">,</span>
                <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="n">stages</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">stages</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
        <span class="n">MultiPathWayWithFuse</span><span class="p">(</span>
            <span class="n">multipathway_blocks</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">stems</span><span class="p">),</span>
            <span class="n">multipathway_fusion</span><span class="o">=</span><span class="n">fusion_builder</span><span class="p">(</span>
                <span class="n">fusion_dim_in</span><span class="o">=</span><span class="n">stem_dim_outs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                <span class="n">stage_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="p">),</span>
        <span class="p">)</span>
    <span class="p">)</span>

    <span class="c1"># Build stages blocks.</span>
    <span class="n">stage_dim_in</span> <span class="o">=</span> <span class="n">stem_dim_outs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">stage_dim_out</span> <span class="o">=</span> <span class="n">stage_dim_in</span> <span class="o">*</span> <span class="mi">4</span>
    <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">stage_depths</span><span class="p">)):</span>
        <span class="n">pathway_stage_dim_in</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">stage_dim_in</span>
            <span class="o">+</span> <span class="n">stage_dim_in</span>
            <span class="o">*</span> <span class="n">slowfast_conv_channel_fusion_ratio</span>
            <span class="o">//</span> <span class="n">slowfast_channel_reduction_ratio</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
        <span class="p">]</span>
        <span class="n">pathway_stage_dim_inner</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">stage_dim_out</span> <span class="o">//</span> <span class="mi">4</span><span class="p">,</span>
        <span class="p">]</span>
        <span class="n">pathway_stage_dim_out</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">stage_dim_out</span><span class="p">,</span>
        <span class="p">]</span>
        <span class="k">for</span> <span class="n">reduction_ratio</span> <span class="ow">in</span> <span class="n">slowfast_channel_reduction_ratio</span><span class="p">:</span>
            <span class="n">pathway_stage_dim_in</span> <span class="o">=</span> <span class="n">pathway_stage_dim_in</span> <span class="o">+</span> <span class="p">[</span>
                <span class="n">stage_dim_in</span> <span class="o">//</span> <span class="n">reduction_ratio</span>
            <span class="p">]</span>
            <span class="n">pathway_stage_dim_inner</span> <span class="o">=</span> <span class="n">pathway_stage_dim_inner</span> <span class="o">+</span> <span class="p">[</span>
                <span class="n">stage_dim_out</span> <span class="o">//</span> <span class="mi">4</span> <span class="o">//</span> <span class="n">reduction_ratio</span>
            <span class="p">]</span>
            <span class="n">pathway_stage_dim_out</span> <span class="o">=</span> <span class="n">pathway_stage_dim_out</span> <span class="o">+</span> <span class="p">[</span>
                <span class="n">stage_dim_out</span> <span class="o">//</span> <span class="n">reduction_ratio</span>
            <span class="p">]</span>

        <span class="n">stage</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">pathway_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">_num_pathway</span><span class="p">):</span>
            <span class="n">depth</span> <span class="o">=</span> <span class="n">stage_depths</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

            <span class="n">stage_conv_a_stride</span> <span class="o">=</span> <span class="p">(</span><span class="n">stage_temporal_strides</span><span class="p">[</span><span class="n">pathway_idx</span><span class="p">][</span><span class="n">idx</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">stage_conv_b_stride</span> <span class="o">=</span> <span class="p">(</span>
                <span class="mi">1</span><span class="p">,</span>
                <span class="n">stage_spatial_strides</span><span class="p">[</span><span class="n">pathway_idx</span><span class="p">][</span><span class="n">idx</span><span class="p">],</span>
                <span class="n">stage_spatial_strides</span><span class="p">[</span><span class="n">pathway_idx</span><span class="p">][</span><span class="n">idx</span><span class="p">],</span>
            <span class="p">)</span>
            <span class="n">stage</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">create_res_stage</span><span class="p">(</span>
                    <span class="n">depth</span><span class="o">=</span><span class="n">depth</span><span class="p">,</span>
                    <span class="n">dim_in</span><span class="o">=</span><span class="n">pathway_stage_dim_in</span><span class="p">[</span><span class="n">pathway_idx</span><span class="p">],</span>
                    <span class="n">dim_inner</span><span class="o">=</span><span class="n">pathway_stage_dim_inner</span><span class="p">[</span><span class="n">pathway_idx</span><span class="p">],</span>
                    <span class="n">dim_out</span><span class="o">=</span><span class="n">pathway_stage_dim_out</span><span class="p">[</span><span class="n">pathway_idx</span><span class="p">],</span>
                    <span class="n">bottleneck</span><span class="o">=</span><span class="n">bottleneck</span><span class="p">[</span><span class="n">pathway_idx</span><span class="p">][</span><span class="n">idx</span><span class="p">],</span>
                    <span class="n">conv_a_kernel_size</span><span class="o">=</span><span class="n">stage_conv_a_kernel_sizes</span><span class="p">[</span><span class="n">pathway_idx</span><span class="p">][</span><span class="n">idx</span><span class="p">],</span>
                    <span class="n">conv_a_stride</span><span class="o">=</span><span class="n">stage_conv_a_stride</span><span class="p">,</span>
                    <span class="n">conv_a_padding</span><span class="o">=</span><span class="p">[</span>
                        <span class="n">size</span> <span class="o">//</span> <span class="mi">2</span>
                        <span class="k">for</span> <span class="n">size</span> <span class="ow">in</span> <span class="n">stage_conv_a_kernel_sizes</span><span class="p">[</span><span class="n">pathway_idx</span><span class="p">][</span><span class="n">idx</span><span class="p">]</span>
                    <span class="p">],</span>
                    <span class="n">conv_b_kernel_size</span><span class="o">=</span><span class="n">stage_conv_b_kernel_sizes</span><span class="p">[</span><span class="n">pathway_idx</span><span class="p">][</span><span class="n">idx</span><span class="p">],</span>
                    <span class="n">conv_b_stride</span><span class="o">=</span><span class="n">stage_conv_b_stride</span><span class="p">,</span>
                    <span class="n">conv_b_padding</span><span class="o">=</span><span class="p">[</span>
                        <span class="n">size</span> <span class="o">//</span> <span class="mi">2</span>
                        <span class="k">for</span> <span class="n">size</span> <span class="ow">in</span> <span class="n">stage_conv_b_kernel_sizes</span><span class="p">[</span><span class="n">pathway_idx</span><span class="p">][</span><span class="n">idx</span><span class="p">]</span>
                    <span class="p">],</span>
                    <span class="n">conv_b_num_groups</span><span class="o">=</span><span class="n">stage_conv_b_num_groups</span><span class="p">[</span><span class="n">pathway_idx</span><span class="p">][</span><span class="n">idx</span><span class="p">],</span>
                    <span class="n">conv_b_dilation</span><span class="o">=</span><span class="n">stage_conv_b_dilations</span><span class="p">[</span><span class="n">pathway_idx</span><span class="p">][</span><span class="n">idx</span><span class="p">],</span>
                    <span class="n">norm</span><span class="o">=</span><span class="n">norm</span><span class="p">,</span>
                    <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="n">stages</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">MultiPathWayWithFuse</span><span class="p">(</span>
                <span class="n">multipathway_blocks</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">stage</span><span class="p">),</span>
                <span class="n">multipathway_fusion</span><span class="o">=</span><span class="n">fusion_builder</span><span class="p">(</span>
                    <span class="n">fusion_dim_in</span><span class="o">=</span><span class="n">stage_dim_out</span><span class="p">,</span>
                    <span class="n">stage_idx</span><span class="o">=</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
                <span class="p">),</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="n">stage_dim_in</span> <span class="o">=</span> <span class="n">stage_dim_out</span>
        <span class="n">stage_dim_out</span> <span class="o">=</span> <span class="n">stage_dim_out</span> <span class="o">*</span> <span class="mi">2</span>

    <span class="k">if</span> <span class="n">head_pool</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">pool_model</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">elif</span> <span class="n">head_pool</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveAvgPool3d</span><span class="p">:</span>
        <span class="n">pool_model</span> <span class="o">=</span> <span class="p">[</span><span class="n">head_pool</span><span class="p">(</span><span class="n">head_output_size</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">_num_pathway</span><span class="p">)]</span>
    <span class="k">elif</span> <span class="n">head_pool</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">AvgPool3d</span><span class="p">:</span>
        <span class="n">pool_model</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">head_pool</span><span class="p">(</span>
                <span class="n">kernel_size</span><span class="o">=</span><span class="n">head_pool_kernel_sizes</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span>
                <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">_num_pathway</span><span class="p">)</span>
        <span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported pool_model type </span><span class="si">{</span><span class="n">pool_model</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">stages</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">PoolConcatPathway</span><span class="p">(</span><span class="n">retain_list</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">pool</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">pool_model</span><span class="p">)))</span>
    <span class="n">head_in_features</span> <span class="o">=</span> <span class="n">stage_dim_in</span>
    <span class="k">for</span> <span class="n">reduction_ratio</span> <span class="ow">in</span> <span class="n">slowfast_channel_reduction_ratio</span><span class="p">:</span>
        <span class="n">head_in_features</span> <span class="o">=</span> <span class="n">head_in_features</span> <span class="o">+</span> <span class="n">stage_dim_in</span> <span class="o">//</span> <span class="n">reduction_ratio</span>
    <span class="n">stages</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
        <span class="n">create_res_basic_head</span><span class="p">(</span>
            <span class="n">in_features</span><span class="o">=</span><span class="n">head_in_features</span><span class="p">,</span>
            <span class="n">out_features</span><span class="o">=</span><span class="n">model_num_class</span><span class="p">,</span>
            <span class="n">pool</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">output_size</span><span class="o">=</span><span class="n">head_output_size</span><span class="p">,</span>
            <span class="n">dropout_rate</span><span class="o">=</span><span class="n">dropout_rate</span><span class="p">,</span>
            <span class="n">activation</span><span class="o">=</span><span class="n">head_activation</span><span class="p">,</span>
            <span class="n">output_with_global_average</span><span class="o">=</span><span class="n">head_output_with_global_average</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">Net</span><span class="p">(</span><span class="n">blocks</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">stages</span><span class="p">))</span></div>


<span class="c1"># TODO: move to pytorchvideo/layer once we have a common.py</span>
<div class="viewcode-block" id="PoolConcatPathway"><a class="viewcode-back" href="../../../api/models/slowfast.html#pytorchvideo.models.slowfast.PoolConcatPathway">[docs]</a><span class="k">class</span> <span class="nc">PoolConcatPathway</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Given a list of tensors, perform optional spatio-temporal pool and concatenate the</span>
<span class="sd">        tensors along the channel dimension.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="PoolConcatPathway.__init__"><a class="viewcode-back" href="../../../api/models/slowfast.html#pytorchvideo.models.slowfast.PoolConcatPathway.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">retain_list</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">pool</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            retain_list (bool): if True, return the concatenated tensor in a list.</span>
<span class="sd">            pool (nn.module_list): if not None, list of pooling models for different</span>
<span class="sd">                pathway before performing concatenation.</span>
<span class="sd">            dim (int): dimension to performance concatenation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">set_attributes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">locals</span><span class="p">())</span></div>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">ind</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)):</span>
            <span class="k">if</span> <span class="n">x</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">x</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">[</span><span class="n">ind</span><span class="p">](</span><span class="n">x</span><span class="p">[</span><span class="n">ind</span><span class="p">])</span>
                <span class="n">output</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">ind</span><span class="p">])</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">retain_list</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span></div>


<span class="k">class</span> <span class="nc">FastToSlowFusionBuilder</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">slowfast_channel_reduction_ratio</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">conv_fusion_channel_ratio</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">conv_kernel_size</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
        <span class="n">conv_stride</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
        <span class="n">norm</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm3d</span><span class="p">,</span>
        <span class="n">norm_eps</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-5</span><span class="p">,</span>
        <span class="n">norm_momentum</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
        <span class="n">activation</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span>
        <span class="n">max_stage_idx</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Given a list of two tensors from Slow pathway and Fast pathway, fusion information</span>
<span class="sd">        from the Fast pathway to the Slow on through a convolution followed by a</span>
<span class="sd">        concatenation, then return the fused list of tensors from Slow and Fast pathway in</span>
<span class="sd">        order.</span>
<span class="sd">        Args:</span>
<span class="sd">            slowfast_channel_reduction_ratio (int): Reduction ratio from the stage dimension.</span>
<span class="sd">                Used to compute conv_dim_in = fusion_dim_in // slowfast_channel_reduction_ratio</span>
<span class="sd">            conv_fusion_channel_ratio (int): channel ratio for the convolution used to fuse</span>
<span class="sd">                from Fast pathway to Slow pathway.</span>
<span class="sd">            conv_kernel_size (int): kernel size of the convolution used to fuse from Fast</span>
<span class="sd">                pathway to Slow pathway.</span>
<span class="sd">            conv_stride (int): stride size of the convolution used to fuse from Fast pathway</span>
<span class="sd">                to Slow pathway.</span>
<span class="sd">            norm (callable): a callable that constructs normalization layer, examples</span>
<span class="sd">                include nn.BatchNorm3d, None (not performing normalization).</span>
<span class="sd">            norm_eps (float): normalization epsilon.</span>
<span class="sd">            norm_momentum (float): normalization momentum.</span>
<span class="sd">            activation (callable): a callable that constructs activation layer, examples</span>
<span class="sd">                include: nn.ReLU, nn.Softmax, nn.Sigmoid, and None (not performing</span>
<span class="sd">                activation).</span>
<span class="sd">            max_stage_idx (int): Returns identity module if we exceed this</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">set_attributes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">locals</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">create_module</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fusion_dim_in</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">stage_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Creates the module for the given stage</span>
<span class="sd">        Args:</span>
<span class="sd">            fusion_dim_in (int): input stage dimension</span>
<span class="sd">            stage_idx (int): which stage this is</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">stage_idx</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_stage_idx</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>

        <span class="n">conv_dim_in</span> <span class="o">=</span> <span class="n">fusion_dim_in</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">slowfast_channel_reduction_ratio</span>
        <span class="n">conv_fast_to_slow</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv3d</span><span class="p">(</span>
            <span class="n">conv_dim_in</span><span class="p">,</span>
            <span class="nb">int</span><span class="p">(</span><span class="n">conv_dim_in</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_fusion_channel_ratio</span><span class="p">),</span>
            <span class="n">kernel_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">conv_kernel_size</span><span class="p">,</span>
            <span class="n">stride</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">conv_stride</span><span class="p">,</span>
            <span class="n">padding</span><span class="o">=</span><span class="p">[</span><span class="n">k_size</span> <span class="o">//</span> <span class="mi">2</span> <span class="k">for</span> <span class="n">k_size</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_kernel_size</span><span class="p">],</span>
            <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">norm_module</span> <span class="o">=</span> <span class="p">(</span>
            <span class="kc">None</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="ow">is</span> <span class="kc">None</span>
            <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span>
                <span class="n">num_features</span><span class="o">=</span><span class="n">conv_dim_in</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_fusion_channel_ratio</span><span class="p">,</span>
                <span class="n">eps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">norm_eps</span><span class="p">,</span>
                <span class="n">momentum</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">norm_momentum</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="n">activation_module</span> <span class="o">=</span> <span class="kc">None</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">FuseFastToSlow</span><span class="p">(</span>
            <span class="n">conv_fast_to_slow</span><span class="o">=</span><span class="n">conv_fast_to_slow</span><span class="p">,</span>
            <span class="n">norm</span><span class="o">=</span><span class="n">norm_module</span><span class="p">,</span>
            <span class="n">activation</span><span class="o">=</span><span class="n">activation_module</span><span class="p">,</span>
        <span class="p">)</span>


<div class="viewcode-block" id="FuseFastToSlow"><a class="viewcode-back" href="../../../api/models/slowfast.html#pytorchvideo.models.slowfast.FuseFastToSlow">[docs]</a><span class="k">class</span> <span class="nc">FuseFastToSlow</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Given a list of two tensors from Slow pathway and Fast pathway, fusion information</span>
<span class="sd">    from the Fast pathway to the Slow on through a convolution followed by a</span>
<span class="sd">    concatenation, then return the fused list of tensors from Slow and Fast pathway in</span>
<span class="sd">    order.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="FuseFastToSlow.__init__"><a class="viewcode-back" href="../../../api/models/slowfast.html#pytorchvideo.models.slowfast.FuseFastToSlow.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">conv_fast_to_slow</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
        <span class="n">norm</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">activation</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            conv_fast_to_slow (nn.module): convolution to perform fusion.</span>
<span class="sd">            norm (nn.module): normalization module.</span>
<span class="sd">            activation (torch.nn.modules): activation module.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">set_attributes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">locals</span><span class="p">())</span></div>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x_s</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">x_f</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">fuse</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_fast_to_slow</span><span class="p">(</span><span class="n">x_f</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">fuse</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">fuse</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">fuse</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">fuse</span><span class="p">)</span>
        <span class="n">x_s_fuse</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">x_s</span><span class="p">,</span> <span class="n">fuse</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">x_s_fuse</span><span class="p">,</span> <span class="n">x_f</span><span class="p">]</span></div>
</pre></div>

             </article>
             
            </div>
            <!-- <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2021, PyTorchVideo contributors.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>
 -->
          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
         <script src="../../../_static/jquery.js"></script>
         <script src="../../../_static/underscore.js"></script>
         <script src="../../../_static/doctools.js"></script>
         <script src="../../../_static/language_data.js"></script>
     

  

  <script type="text/javascript" src="../../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->


  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorchvideo.org" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorchvideo.org">Home</a>
          </li>
          <li>
            <a href="https://pytorchvideo.org/docs/tutorial_overview">Tutorials</a>
          </li>
          <li>
            <a href="https://github.com/facebookresearch/pytorchvideo/">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>
  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>