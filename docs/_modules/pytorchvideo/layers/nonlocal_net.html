


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>pytorchvideo.layers.nonlocal_net &mdash; PyTorchVideo  documentation</title>
  

  
  
    <link rel="shortcut icon" href="../../../_static/favicon.png"/>
  
  
  
    <link rel="canonical" href="https://pytorchvideo.org/docs/_modules/pytorchvideo/layers/nonlocal_net.html"/>
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" /> -->
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 

  
  <script src="../../../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorchvideo.org" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorchvideo.org">Home</a>
          </li>
          <li>
            <a href="https://pytorchvideo.org/docs/tutorial_overview">Tutorials</a>
          </li>
          <li>
            <a href="https://github.com/facebookresearch/pytorchvideo/">Github</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>


<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../docs/models.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../docs/model_zoo.html">Model Zoo and Benchmarks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/models/index.html">Models API</a></li>
</ul>
<p class="caption"><span class="caption-text">Data</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../docs/data.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../docs/data_preparation.html">Data Preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/data/index.html">Data API</a></li>
</ul>
<p class="caption"><span class="caption-text">Transforms</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../docs/transforms.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/transforms/index.html">Transforms API</a></li>
</ul>
<p class="caption"><span class="caption-text">Layers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../docs/layers.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/layers/index.html">Layers API</a></li>
</ul>
<p class="caption"><span class="caption-text">Accelerator</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../docs/accelerator.html">Overview</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="../../index.html">Module code</a> &gt;</li>
        
      <li>pytorchvideo.layers.nonlocal_net</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <h1>Source code for pytorchvideo.layers.nonlocal_net</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.</span>

<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Iterable</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Tuple</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">pytorchvideo.layers.utils</span> <span class="kn">import</span> <span class="n">set_attributes</span>


<div class="viewcode-block" id="NonLocal"><a class="viewcode-back" href="../../../api/layers/layers.html#pytorchvideo.layers.nonlocal_net.NonLocal">[docs]</a><span class="k">class</span> <span class="nc">NonLocal</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Builds Non-local Neural Networks as a generic family of building</span>
<span class="sd">    blocks for capturing long-range dependencies. Non-local Network</span>
<span class="sd">    computes the response at a position as a weighted sum of the</span>
<span class="sd">    features at all positions. This building block can be plugged into</span>
<span class="sd">    many computer vision architectures.</span>
<span class="sd">    More details in the paper:</span>
<span class="sd">    Wang, Xiaolong, Ross Girshick, Abhinav Gupta, and Kaiming He.</span>
<span class="sd">    &quot;Non-local neural networks.&quot;</span>
<span class="sd">    In Proceedings of the IEEE conference on CVPR, 2018.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">conv_theta</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
        <span class="n">conv_phi</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
        <span class="n">conv_g</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
        <span class="n">conv_out</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
        <span class="n">pool</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">norm</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">instantiation</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;dot_product&quot;</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">set_attributes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">locals</span><span class="p">())</span>
        <span class="k">assert</span> <span class="kc">None</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="n">conv_theta</span><span class="p">,</span> <span class="n">conv_phi</span><span class="p">,</span> <span class="n">conv_g</span><span class="p">,</span> <span class="n">conv_out</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">instantiation</span> <span class="ow">in</span> <span class="p">(</span>
            <span class="s2">&quot;dot_product&quot;</span><span class="p">,</span>
            <span class="s2">&quot;softmax&quot;</span><span class="p">,</span>
        <span class="p">),</span> <span class="s2">&quot;Unknown norm type </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">instantiation</span><span class="p">)</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="nb">len</span><span class="p">(</span>
                <span class="p">{</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">conv_theta</span><span class="o">.</span><span class="n">out_channels</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">conv_phi</span><span class="o">.</span><span class="n">out_channels</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">conv_g</span><span class="o">.</span><span class="n">out_channels</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">conv_out</span><span class="o">.</span><span class="n">in_channels</span><span class="p">,</span>
                <span class="p">}</span>
            <span class="p">)</span>
            <span class="o">==</span> <span class="mi">1</span>
        <span class="p">),</span> <span class="s2">&quot;Nonlocal convolution&#39;s input/ output dimension mismatch.&quot;</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">dim_inner</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_theta</span><span class="o">.</span><span class="n">out_channels</span>

        <span class="n">x_identity</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>

        <span class="n">theta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_theta</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># Perform temporal-spatial pooling to reduce the computation.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">phi</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_phi</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">g</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_g</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">theta</span> <span class="o">=</span> <span class="n">theta</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">dim_inner</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">phi</span> <span class="o">=</span> <span class="n">phi</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">dim_inner</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">g</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">dim_inner</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># (N, C, TxHxW) x (N, C, TxHxW) =&gt; (N, TxHxW, TxHxW).</span>
        <span class="n">theta_phi</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;nct,ncp-&gt;ntp&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">phi</span><span class="p">))</span>
        <span class="c1"># For original Non-local paper, there are two main ways to normalize</span>
        <span class="c1"># the affinity tensor:</span>
        <span class="c1">#   1) Softmax normalization (norm on exp).</span>
        <span class="c1">#   2) dot_product normalization.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">instantiation</span> <span class="o">==</span> <span class="s2">&quot;softmax&quot;</span><span class="p">:</span>
            <span class="c1"># Normalizing the affinity tensor theta_phi before softmax.</span>
            <span class="n">theta_phi</span> <span class="o">=</span> <span class="n">theta_phi</span> <span class="o">*</span> <span class="p">(</span><span class="n">dim_inner</span> <span class="o">**</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">)</span>
            <span class="n">theta_phi</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">theta_phi</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">instantiation</span> <span class="o">==</span> <span class="s2">&quot;dot_product&quot;</span><span class="p">:</span>
            <span class="n">spatial_temporal_dim</span> <span class="o">=</span> <span class="n">theta_phi</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
            <span class="n">theta_phi</span> <span class="o">=</span> <span class="n">theta_phi</span> <span class="o">/</span> <span class="n">spatial_temporal_dim</span>

        <span class="c1"># (N, TxHxW, TxHxW) * (N, C, TxHxW) =&gt; (N, C, TxHxW).</span>
        <span class="n">theta_phi_g</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;ntg,ncg-&gt;nct&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">theta_phi</span><span class="p">,</span> <span class="n">g</span><span class="p">))</span>
        <span class="c1"># (N, C, TxHxW) =&gt; (N, C, T, H, W).</span>
        <span class="n">theta_phi_g</span> <span class="o">=</span> <span class="n">theta_phi_g</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">dim_inner</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span>
        <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_out</span><span class="p">(</span><span class="n">theta_phi_g</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x_identity</span> <span class="o">+</span> <span class="n">p</span></div>


<div class="viewcode-block" id="create_nonlocal"><a class="viewcode-back" href="../../../api/layers/layers.html#pytorchvideo.layers.nonlocal_net.create_nonlocal">[docs]</a><span class="k">def</span> <span class="nf">create_nonlocal</span><span class="p">(</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="c1"># Nonlocal configs.</span>
    <span class="n">dim_in</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">dim_inner</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">pool_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
    <span class="n">instantiation</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;softmax&quot;</span><span class="p">,</span>
    <span class="c1"># Norm configs.</span>
    <span class="n">norm</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm3d</span><span class="p">,</span>
    <span class="n">norm_eps</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-5</span><span class="p">,</span>
    <span class="n">norm_momentum</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Builds Non-local Neural Networks as a generic family of building</span>
<span class="sd">    blocks for capturing long-range dependencies. Non-local Network</span>
<span class="sd">    computes the response at a position as a weighted sum of the</span>
<span class="sd">    features at all positions. This building block can be plugged into</span>
<span class="sd">    many computer vision architectures.</span>
<span class="sd">    More details in the paper: https://arxiv.org/pdf/1711.07971</span>
<span class="sd">    Args:</span>
<span class="sd">        dim_in (int): number of dimension for the input.</span>
<span class="sd">        dim_inner (int): number of dimension inside of the Non-local block.</span>
<span class="sd">        pool_size (tuple[int]): the kernel size of spatial temporal pooling,</span>
<span class="sd">            temporal pool kernel size, spatial pool kernel size, spatial pool kernel</span>
<span class="sd">            size in order. By default pool_size is None, then there would be no pooling</span>
<span class="sd">            used.</span>
<span class="sd">        instantiation (string): supports two different instantiation method:</span>
<span class="sd">            &quot;dot_product&quot;: normalizing correlation matrix with L2.</span>
<span class="sd">            &quot;softmax&quot;: normalizing correlation matrix with Softmax.</span>
<span class="sd">        norm (nn.Module): nn.Module for the normalization layer. The default is</span>
<span class="sd">            nn.BatchNorm3d.</span>
<span class="sd">        norm_eps (float): normalization epsilon.</span>
<span class="sd">        norm_momentum (float): normalization momentum.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">pool_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">pool_size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">pool_size</span><span class="p">,</span> <span class="n">Iterable</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">norm</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">norm_model</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">norm_model</span> <span class="o">=</span> <span class="n">norm</span><span class="p">(</span><span class="n">num_features</span><span class="o">=</span><span class="n">dim_in</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="n">norm_eps</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="n">norm_momentum</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">size</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">size</span> <span class="ow">in</span> <span class="n">pool_size</span><span class="p">):</span>
        <span class="n">pool_model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool3d</span><span class="p">(</span>
            <span class="n">kernel_size</span><span class="o">=</span><span class="n">pool_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">pool_size</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">pool_model</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">return</span> <span class="n">NonLocal</span><span class="p">(</span>
        <span class="n">conv_theta</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv3d</span><span class="p">(</span><span class="n">dim_in</span><span class="p">,</span> <span class="n">dim_inner</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
        <span class="n">conv_phi</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv3d</span><span class="p">(</span><span class="n">dim_in</span><span class="p">,</span> <span class="n">dim_inner</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
        <span class="n">conv_g</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv3d</span><span class="p">(</span><span class="n">dim_in</span><span class="p">,</span> <span class="n">dim_inner</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
        <span class="n">conv_out</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv3d</span><span class="p">(</span><span class="n">dim_inner</span><span class="p">,</span> <span class="n">dim_in</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
        <span class="n">pool</span><span class="o">=</span><span class="n">pool_model</span><span class="p">,</span>
        <span class="n">norm</span><span class="o">=</span><span class="n">norm_model</span><span class="p">,</span>
        <span class="n">instantiation</span><span class="o">=</span><span class="n">instantiation</span><span class="p">,</span>
    <span class="p">)</span></div>
</pre></div>

             </article>
             
            </div>
            <!-- <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2021, PyTorchVideo contributors.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>
 -->
          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
         <script src="../../../_static/jquery.js"></script>
         <script src="../../../_static/underscore.js"></script>
         <script src="../../../_static/doctools.js"></script>
         <script src="../../../_static/language_data.js"></script>
     

  

  <script type="text/javascript" src="../../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->


  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebookâ€™s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorchvideo.org" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorchvideo.org">Home</a>
          </li>
          <li>
            <a href="https://pytorchvideo.org/docs/tutorial_overview">Tutorials</a>
          </li>
          <li>
            <a href="https://github.com/facebookresearch/pytorchvideo/">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>
  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>