


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>id: tutorial_accelerator_use_accelerator_model_zoo title: Use PytorchVideo/Accelerator Model Zoo &mdash; PyTorchVideo  documentation</title>
  

  
  
    <link rel="shortcut icon" href="../_static/favicon.png"/>
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 

  
  <script src="../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorchvideo.org" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorchvideo.org">Home</a>
          </li>
          <li>
            <a href="https://pytorchvideo.org/docs/tutorial_overview">Tutorials</a>
          </li>
          <li>
            <a href="https://github.com/facebookresearch/pytorchvideo/">Github</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>


<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="models.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_zoo.html">Model Zoo and Benchmarks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/models/index.html">Models API</a></li>
</ul>
<p class="caption"><span class="caption-text">Data</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="data.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="data_preparation.html">Data Preparation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/data/index.html">Data API</a></li>
</ul>
<p class="caption"><span class="caption-text">Transforms</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="transforms.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/transforms/index.html">Transforms API</a></li>
</ul>
<p class="caption"><span class="caption-text">Layers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="layers.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/layers/index.html">Layers API</a></li>
</ul>
<p class="caption"><span class="caption-text">Accelerator</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="accelerator.html">Overview</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
      <li>id: tutorial_accelerator_use_accelerator_model_zoo
title: Use PytorchVideo/Accelerator Model Zoo</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="../_sources/docs/tutorial_accelerator_use_accelerator_model_zoo.md.txt" rel="nofollow"><img src="../_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <hr class="docutils" />
<div class="section" id="id-tutorial-accelerator-use-accelerator-model-zoo-title-use-pytorchvideo-accelerator-model-zoo">
<h1>id: tutorial_accelerator_use_accelerator_model_zoo
title: Use PytorchVideo/Accelerator Model Zoo<a class="headerlink" href="#id-tutorial-accelerator-use-accelerator-model-zoo-title-use-pytorchvideo-accelerator-model-zoo" title="Permalink to this headline">¶</a></h1>
</div>
<div class="section" id="introduction">
<h1>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h1>
<p>This tutorial goes through how to use model zoo provided by PytorchVideo/Accelerator. To use model zoo in PytorchVideo/Accelerator, we should generally follow several steps:</p>
<ul class="simple">
<li><p>Use model builder to build selected model;</p></li>
<li><p>Load pretrain checkpoint;</p></li>
<li><p>(Optional) Finetune;</p></li>
<li><p>Deploy.</p></li>
</ul>
</div>
<div class="section" id="use-model-builder-to-build-selected-model">
<h1>Use model builder to build selected model<a class="headerlink" href="#use-model-builder-to-build-selected-model" title="Permalink to this headline">¶</a></h1>
<p>We use model builder in PytorchVideo/Accelerator model zoo to build pre-defined efficient model. Here we use EfficientX3D-XS (for mobile_cpu) as an example. For more available models and details, please refer to [this page].</p>
<p>EfficientX3D-XS is an implementation of X3D-XS network as described in <a class="reference external" href="https://arxiv.org/abs/2004.04730">X3D paper</a> using efficient blocks. It is arithmetically equivalent with X3D-XS, but our benchmark on mobile phone shows 4.6X latency reduction compared with vanilla implementation.</p>
<p>In order to build EfficientX3D-XS, we simply do the following:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pytorchvideo.models.accelerator.mobile_cpu.efficient_x3d</span> <span class="kn">import</span> <span class="n">EfficientX3d</span>
<span class="n">model_efficient_x3d_xs</span> <span class="o">=</span> <span class="n">EfficientX3d</span><span class="p">(</span><span class="n">expansion</span><span class="o">=</span><span class="s1">&#39;XS&#39;</span><span class="p">,</span> <span class="n">head_act</span><span class="o">=</span><span class="s1">&#39;identity&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>Note that now the efficient blocks in the model are in original form, so the model is good for further training.</p>
</div>
<div class="section" id="load-pretrain-checkpoint-and-optional-finetune">
<h1>Load pretrain checkpoint and (optional) finetune<a class="headerlink" href="#load-pretrain-checkpoint-and-optional-finetune" title="Permalink to this headline">¶</a></h1>
<p>For each model in model zoo, we provide pretrain checkpoint state_dict for model in original form. See [this page] for details about checkpoints and where to download them.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.hub</span> <span class="kn">import</span> <span class="n">load_state_dict_from_url</span>
<span class="n">checkpoint_path</span> <span class="o">=</span> <span class="s1">&#39;https://dl.fbaipublicfiles.com/pytorchvideo/model_zoo/kinetics/efficient_x3d_xs_original_form.pyth&#39;</span>
<span class="n">checkpoint</span> <span class="o">=</span> <span class="n">load_state_dict_from_url</span><span class="p">(</span><span class="n">checkpoint_path</span><span class="p">)</span>

<span class="n">model_efficient_x3d_xs</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>
</pre></div>
</div>
<p>Now the model is ready for fine-tune.</p>
</div>
<div class="section" id="deploy">
<h1>Deploy<a class="headerlink" href="#deploy" title="Permalink to this headline">¶</a></h1>
<p>Now the model is ready to deploy. First of all, let’s convert the model into deploy form. In order to do that, we need to use <code class="docutils literal notranslate"><span class="pre">convert_to_deployable_form</span></code> utility and provide an example input tensor to the model. Note that once the model is converted into deploy form, the input size should be the same as the example input tensor size during conversion.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">pytorchvideo.accelerator.deployment.mobile_cpu.utils.model_conversion</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">convert_to_deployable_form</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">input_blob_size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">160</span><span class="p">,</span> <span class="mi">160</span><span class="p">)</span>
<span class="n">input_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">input_blob_size</span><span class="p">)</span>
<span class="n">model_efficient_x3d_xs_deploy</span> <span class="o">=</span> <span class="n">convert_to_deployable_form</span><span class="p">(</span><span class="n">model_efficient_x3d_xs</span><span class="p">,</span> <span class="n">input_tensor</span><span class="p">)</span>
</pre></div>
</div>
<p>Next we have two options: either deploy floating point model, or quantize model into int8 and then deploy.</p>
<p>Let’s first assume we want to deploy floating point model. In this case, all we need to do is to export jit trace and then apply <code class="docutils literal notranslate"><span class="pre">optimize_for_mobile</span></code> for final optimization.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils.mobile_optimizer</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">optimize_for_mobile</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">traced_model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">model_efficient_x3d_xs_deploy</span><span class="p">,</span> <span class="n">input_tensor</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">traced_model_opt</span> <span class="o">=</span> <span class="n">optimize_for_mobile</span><span class="p">(</span><span class="n">traced_model</span><span class="p">)</span>
<span class="c1"># Here we can save the traced_model_opt to JIT file using traced_model_opt.save(&lt;file_path&gt;)</span>
</pre></div>
</div>
<p>Alternatively, we may also want to deploy a quantized model. Efficient blocks are quantization-friendly by design - just wrap the model in deploy form with <code class="docutils literal notranslate"><span class="pre">QuantStub/DeQuantStub</span></code> and it is ready for Pytorch eager mode quantization.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Wrapper class for adding QuantStub/DeQuantStub.</span>
<span class="k">class</span> <span class="nc">quant_stub_wrapper</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module_in</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">quant</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">quantization</span><span class="o">.</span><span class="n">QuantStub</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">module_in</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dequant</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">quantization</span><span class="o">.</span><span class="n">DeQuantStub</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">quant</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dequant</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model_efficient_x3d_xs_deploy_quant_stub_wrapper</span> <span class="o">=</span> <span class="n">quant_stub_wrapper</span><span class="p">(</span><span class="n">model_efficient_x3d_xs_deploy</span><span class="p">)</span>
</pre></div>
</div>
<p>Preparation step of quantization. Fusion has been done for efficient blocks automatically during <code class="docutils literal notranslate"><span class="pre">convert_to_deployable_form</span></code>, so we can just proceed to <code class="docutils literal notranslate"><span class="pre">torch.quantization.prepare</span></code></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model_efficient_x3d_xs_deploy_quant_stub_wrapper</span><span class="o">.</span><span class="n">qconfig</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">quantization</span><span class="o">.</span><span class="n">default_qconfig</span>
<span class="n">model_efficient_x3d_xs_deploy_quant_stub_wrapper_prepared</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">quantization</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model_efficient_x3d_xs_deploy_quant_stub_wrapper</span><span class="p">)</span>
</pre></div>
</div>
<p>Calibration and quantization. After preparation we will do calibration of quantization by feeding calibration dataset (skipped here) and then do quantization.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># calibration is skipped here.</span>
<span class="n">model_efficient_x3d_xs_deploy_quant_stub_wrapper_quantized</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">quantization</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="n">model_efficient_x3d_xs_deploy_quant_stub_wrapper_prepared</span><span class="p">)</span>
</pre></div>
</div>
<p>Then we can export trace of int8 model and deploy on mobile devices.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">traced_model_int8</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">model_efficient_x3d_xs_deploy_quant_stub_wrapper_quantized</span><span class="p">,</span> <span class="n">input_tensor</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">traced_model_int8_opt</span> <span class="o">=</span> <span class="n">optimize_for_mobile</span><span class="p">(</span><span class="n">traced_model_int8</span><span class="p">)</span>
<span class="c1"># Here we can save the traced_model_opt to JIT file using traced_model_int8_opt.save(&lt;file_path&gt;)</span>
</pre></div>
</div>
</div>


             </article>
             
            </div>
            <!-- <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2021, PyTorchVideo contributors.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>
 -->
          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">id: tutorial_accelerator_use_accelerator_model_zoo
title: Use PytorchVideo/Accelerator Model Zoo</a></li>
<li><a class="reference internal" href="#introduction">Introduction</a></li>
<li><a class="reference internal" href="#use-model-builder-to-build-selected-model">Use model builder to build selected model</a></li>
<li><a class="reference internal" href="#load-pretrain-checkpoint-and-optional-finetune">Load pretrain checkpoint and (optional) finetune</a></li>
<li><a class="reference internal" href="#deploy">Deploy</a></li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
         <script src="../_static/jquery.js"></script>
         <script src="../_static/underscore.js"></script>
         <script src="../_static/doctools.js"></script>
         <script src="../_static/language_data.js"></script>
     

  

  <script type="text/javascript" src="../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->


  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorchvideo.org" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorchvideo.org">Home</a>
          </li>
          <li>
            <a href="https://pytorchvideo.org/docs/tutorial_overview">Tutorials</a>
          </li>
          <li>
            <a href="https://github.com/facebookresearch/pytorchvideo/">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>
  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>